{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61ec7982",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"librosa\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"librosa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e490b58b",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "This project aims to solve the problem of automatically classifying musical chords as either major or minor using audio input. Chord identification is a key task in music analysis, and automating it can save time on transcription and harmonic analysis. By using machine learning and music information retrieval (MIR) techniques, the goal is to create a tool that helps musicians, producers, and educators analyze music in real-time. The project focuses on making chord recognition more accessible and efficient, benefiting both students and professionals in the music industry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06932fa2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tools/Methodologies\n",
    "\n",
    "To handle the workflow, I'll use several Python libraries:\n",
    "\n",
    "- [librosa](https://librosa.org/doc/latest/index.html) for extracting audio features, [numpy](https://numpy.org/doc/1.24/reference/index.html#reference) and [pandas](https://pandas.pydata.org/docs/reference/index.html#api) for data manipulation, and os and [Kaggle CLI](https://www.kaggle.com/code/donkeys/kaggle-python-api) to download the data directly into the notebook.\n",
    "- [matplotlib](https://matplotlib.org/stable/api/index.html) and [seaborn](https://seaborn.pydata.org/api.html) for exploring and visualizing features like waveforms and spectrograms.\n",
    "- [scikit-learn](https://scikit-learn.org/stable/api/index.html) for baseline models (e.g., logistic regression, SVM), and [tensorflow](https://www.tensorflow.org/api_docs/python/tf/all_symbols) or [keras](https://keras.io/api/) for building CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c2b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Audio feature extraction\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# for Kaggle CLI\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Machine learning models and utilities\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Deep learning for CNNs\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LSTM, Conv2D, MaxPooling2D, Flatten, Dense, Reshape, Dropout, GlobalAveragePooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ee810",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "The dataset used in this project is sourced from the [Musical Instrument Chord Classification (Audio)](https://www.kaggle.com/datasets/deepcontractor/musical-instrument-chord-classification) dataset on Kaggle. It contains audio files `.wav` format of chords played on two instruments: guitar and piano. The raw data has been scraped from various sources and is already available for download on Kaggle, eliminating the need for manual data collection. The dataset is well-suited for this project, as it provides a clear distinction between major and minor chords, which is the focus of the classification task.\n",
    "\n",
    "The features for the model will be extracted from the audio files using techniques such as Mel-frequency cepstral coefficients (MFCCs) or spectrograms, which capture important frequency and temporal information from the audio signals. Although other individuals may have used this dataset for similar chord classification tasks, this project will build upon existing work by focusing specifically on distinguishing between major and minor chords, potentially improving upon current models or exploring new machine learning techniques for this type of classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61664553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if replicating project\n",
    "# !pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dddf45b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/deepcontractor/musical-instrument-chord-classification\n",
      "Dataset downloaded and extracted to: C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\dataset\n"
     ]
    }
   ],
   "source": [
    "# Load kaggle.json credentials\n",
    "api_config_path = os.path.join(os.getcwd(), 'kaggle.json')\n",
    "with open(api_config_path, 'r') as f:\n",
    "    kaggle_config = json.load(f)\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['KAGGLE_USERNAME'] = kaggle_config['username']\n",
    "os.environ['KAGGLE_KEY'] = kaggle_config['key']\n",
    "\n",
    "# Initialize the Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Ensure the 'dataset' folder exists\n",
    "dataset_dir = os.path.join(os.getcwd(), 'dataset')\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "# Use the Kaggle API to download the dataset\n",
    "api.dataset_download_files('deepcontractor/musical-instrument-chord-classification',\n",
    "                           path=dataset_dir, unzip=True)\n",
    "\n",
    "print(\"Dataset downloaded and extracted to:\", dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0876fed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\da...</td>\n",
       "      <td>Major_0.wav</td>\n",
       "      <td>Major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\da...</td>\n",
       "      <td>Major_1.wav</td>\n",
       "      <td>Major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\da...</td>\n",
       "      <td>Major_10.wav</td>\n",
       "      <td>Major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\da...</td>\n",
       "      <td>Major_100.wav</td>\n",
       "      <td>Major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\da...</td>\n",
       "      <td>Major_101.wav</td>\n",
       "      <td>Major</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path             id  label\n",
       "0  C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\da...    Major_0.wav  Major\n",
       "1  C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\da...    Major_1.wav  Major\n",
       "2  C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\da...   Major_10.wav  Major\n",
       "3  C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\da...  Major_100.wav  Major\n",
       "4  C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\da...  Major_101.wav  Major"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the base directory where the audio files are stored\n",
    "base_dir = os.path.join(os.getcwd(), 'dataset', 'Audio_Files')\n",
    "\n",
    "# Prepare to collect file details\n",
    "file_details = []\n",
    "\n",
    "# Loop through each category directory ('Major' and 'Minor')\n",
    "for category in ['Major', 'Minor']:\n",
    "    category_dir = os.path.join(base_dir, category)\n",
    "    \n",
    "    for filename in os.listdir(category_dir):\n",
    "        if filename.endswith('.wav'):\n",
    "            # Full path to file\n",
    "            file_path = os.path.join(category_dir, filename)\n",
    "            # Append the file path, filename (used as ID), and label to the list\n",
    "            file_details.append({'path': file_path, 'id': filename, 'label': category})\n",
    "\n",
    "# Save collected file details as a DataFrame\n",
    "file_data = pd.DataFrame(file_details)\n",
    "\n",
    "file_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bbebb4",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Feature Extraction Functions:\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4155660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_features(signal=None, sr=22050, hop_length=512, n_fft=2048):\n",
    "    if signal is None or not isinstance(signal, np.ndarray):\n",
    "        print(\"Warning: No valid audio signal provided.\")\n",
    "        return {\n",
    "            'chroma': np.full(12, np.nan),\n",
    "            'mfcc': np.full(20, np.nan),\n",
    "            'spectral_centroid': np.nan,\n",
    "            'zero_crossing_rate': np.nan\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        chroma = librosa.feature.chroma_stft(y=signal, sr=sr, hop_length=hop_length, n_fft=n_fft).mean(axis=1)\n",
    "        mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=20, hop_length=hop_length, n_fft=n_fft).mean(axis=1)\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=signal, sr=sr, hop_length=hop_length).mean()\n",
    "        zero_crossing_rate = librosa.feature.zero_crossing_rate(signal, hop_length=hop_length).mean()\n",
    "\n",
    "        return {\n",
    "            'chroma': chroma,\n",
    "            'mfcc': mfccs,\n",
    "            'spectral_centroid': spectral_centroid,\n",
    "            'zero_crossing_rate': zero_crossing_rate\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during feature extraction: {e}\")\n",
    "        return {\n",
    "            'chroma': np.full(12, np.nan),\n",
    "            'mfcc': np.full(20, np.nan),\n",
    "            'spectral_centroid': np.nan,\n",
    "            'zero_crossing_rate': np.nan\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ceb0fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_harmonics(signal=None, sr=22050, n_fft=2048):\n",
    "    \"\"\"\n",
    "    Extract harmonic frequencies and intervals from an audio signal.\n",
    "    \n",
    "    Parameters:\n",
    "    - signal: Audio signal array (used for both original and augmented data).\n",
    "    - sr: Sample rate.\n",
    "    - n_fft: Number of FFT components.\n",
    "    \n",
    "    Returns:\n",
    "    - harmonic_frequencies and harmonic_intervals\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if signal is None or len(signal) == 0:\n",
    "            raise ValueError(\"No audio signal provided.\")\n",
    "\n",
    "        # Perform STFT to get the frequency spectrum\n",
    "        S = np.abs(librosa.stft(signal, n_fft=n_fft))\n",
    "\n",
    "        # Sum over time frames to get the overall magnitude spectrum\n",
    "        magnitude = np.mean(S, axis=1)\n",
    "\n",
    "        # Frequency bins corresponding to the FFT\n",
    "        frequency = np.fft.fftfreq(len(magnitude), 1/sr)\n",
    "\n",
    "        # Only keep positive frequencies\n",
    "        positive_freq_idxs = np.where(frequency >= 0)\n",
    "        positive_freqs = frequency[positive_freq_idxs]\n",
    "        positive_magnitude = magnitude[positive_freq_idxs]\n",
    "\n",
    "        # Find peaks in the frequency spectrum (harmonics)\n",
    "        peaks, _ = find_peaks(positive_magnitude, height=np.max(positive_magnitude) * 0.1)\n",
    "\n",
    "        # Get the corresponding frequencies of the peaks (harmonic frequencies)\n",
    "        harmonic_frequencies = positive_freqs[peaks]\n",
    "\n",
    "        # Calculate intervals between harmonic frequencies\n",
    "        harmonic_intervals = np.diff(harmonic_frequencies) if len(harmonic_frequencies) > 1 else []\n",
    "\n",
    "        return harmonic_frequencies, harmonic_intervals\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing harmonics for augmented signal: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98081ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mel_spectrogram(signal=None, sr=22050, n_mels=128, hop_length=512, fixed_length=100):\n",
    "    if signal is None or not isinstance(signal, np.ndarray):\n",
    "        print(\"Warning: No valid audio signal provided for mel-spectrogram extraction.\")\n",
    "        return np.full((fixed_length, n_mels), np.nan)\n",
    "\n",
    "    try:\n",
    "        # Generate Mel-spectrogram\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=signal, sr=sr, n_mels=n_mels, hop_length=hop_length)\n",
    "        log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "        # Pad or truncate to the fixed length\n",
    "        log_mel_spectrogram = log_mel_spectrogram.T  # Transpose to (time_steps, n_mels)\n",
    "        if log_mel_spectrogram.shape[0] < fixed_length:\n",
    "            pad_width = fixed_length - log_mel_spectrogram.shape[0]\n",
    "            log_mel_spectrogram = np.pad(log_mel_spectrogram, ((0, pad_width), (0, 0)), mode='constant')\n",
    "        else:\n",
    "            log_mel_spectrogram = log_mel_spectrogram[:fixed_length, :]\n",
    "\n",
    "        return log_mel_spectrogram\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Mel-spectrogram extraction: {e}\")\n",
    "        return np.full((fixed_length, n_mels), np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3511da1b",
   "metadata": {},
   "source": [
    "#### Running Feature Extraction on Origional Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26e6b7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting features for C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\dataset\\Audio_Files\\Major\\Major_285.wav: \n",
      "          id  Label  chroma_1  chroma_2  chroma_3  chroma_4  chroma_5  \\\n",
      "0    Major_0  Major  0.796852  0.417257  0.299810  0.391450  0.769257   \n",
      "1    Major_1  Major  0.723283  0.452638  0.262528  0.236474  0.472363   \n",
      "2   Major_10  Major  0.371833  0.267660  0.125646  0.144663  0.298086   \n",
      "3  Major_100  Major  0.390774  0.934246  0.763238  0.553007  0.418208   \n",
      "4  Major_101  Major  0.207329  0.403518  0.400692  0.461187  0.456608   \n",
      "\n",
      "   chroma_6  chroma_7  chroma_8  ...    mfcc_13    mfcc_14    mfcc_15  \\\n",
      "0  0.475731  0.173122  0.434240  ... -16.763796  -8.383060  -2.931852   \n",
      "1  0.383091  0.316608  0.407608  ...  -4.015803  -3.557462  -3.183057   \n",
      "2  0.462609  0.684176  0.370034  ... -11.326472  -2.769469  -0.272876   \n",
      "3  0.357188  0.244438  0.371424  ... -14.805438 -11.510791 -10.704238   \n",
      "4  0.576159  0.579669  0.570114  ...  -9.541916  -5.118158   0.926334   \n",
      "\n",
      "    mfcc_16    mfcc_17    mfcc_18    mfcc_19    mfcc_20  spectral_centroid  \\\n",
      "0  0.503394  -2.288271 -13.241952 -17.839819  -9.265323         731.644753   \n",
      "1 -3.570750  -4.474475  -3.675622  -2.849134  -4.409894         497.091980   \n",
      "2 -5.870788 -14.207583 -13.337405  -6.933512  -5.560721         608.686444   \n",
      "3 -8.537863  -7.418064  -8.981711 -13.031836 -13.627768         735.732537   \n",
      "4  1.874037  -1.300467  -4.327853  -4.558311  -3.568055         619.950017   \n",
      "\n",
      "   zero_crossing_rate  \n",
      "0            0.021721  \n",
      "1            0.011334  \n",
      "2            0.020248  \n",
      "3            0.024483  \n",
      "4            0.012351  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store feature data\n",
    "feature_data = []\n",
    "\n",
    "# Extract features for each file and store them in a list\n",
    "for index, row in file_data.iterrows():\n",
    "    try:\n",
    "        # Load the original audio signal\n",
    "        signal, sr = librosa.load(row['path'], sr=None)\n",
    "\n",
    "        # Check if the signal is valid\n",
    "        if signal is None or len(signal) == 0:\n",
    "            print(f\"Warning: Empty or invalid audio signal for {row['path']}\")\n",
    "            continue\n",
    "\n",
    "        # Extract features using the updated function\n",
    "        features = extract_audio_features(signal=signal, sr=sr)\n",
    "\n",
    "        if features is not None:\n",
    "            feature_data.append({\n",
    "                'id': row['id'].replace('.wav', ''),\n",
    "                'Label': row['label'],\n",
    "                'chroma': features['chroma'],  # Store chroma features\n",
    "                'mfcc': features['mfcc'],      # Store MFCC features\n",
    "                'spectral_centroid': features['spectral_centroid'],  # Store spectral centroid\n",
    "                'zero_crossing_rate': features['zero_crossing_rate'] # Store zero-crossing rate\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Warning: Feature extraction returned None for {row['path']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features for {row['path']}: {e}\")\n",
    "\n",
    "# Prepare a list to hold each row's dictionary for creating the DataFrame\n",
    "feature_dict_list = []\n",
    "\n",
    "# Determine the number of chroma and MFCC coefficients (12 chroma, 20 MFCCs)\n",
    "n_chroma = 12\n",
    "n_mfcc = 20\n",
    "\n",
    "# Processing each item's features to create a flat dictionary\n",
    "for item in feature_data:\n",
    "    feature_dict = {\n",
    "        'id': item['id'],\n",
    "        'Label': item['Label']\n",
    "    }\n",
    "    \n",
    "    # Store chroma features\n",
    "    for i in range(n_chroma):\n",
    "        feature_dict[f'chroma_{i+1}'] = item['chroma'][i] if i < len(item['chroma']) else np.nan\n",
    "    \n",
    "    # Store MFCC features\n",
    "    for i in range(n_mfcc):\n",
    "        feature_dict[f'mfcc_{i+1}'] = item['mfcc'][i] if i < len(item['mfcc']) else np.nan\n",
    "    \n",
    "    # Store spectral centroid and zero-crossing rate as scalar features\n",
    "    feature_dict['spectral_centroid'] = item['spectral_centroid']\n",
    "    feature_dict['zero_crossing_rate'] = item['zero_crossing_rate']\n",
    "    \n",
    "    feature_dict_list.append(feature_dict)\n",
    "\n",
    "# Create a new DataFrame from the list of dictionaries\n",
    "features_df = pd.DataFrame(feature_dict_list)\n",
    "\n",
    "# Display the first few rows of the new DataFrame to verify\n",
    "print(features_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f506735f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\dataset\\Audio_Files\\Major\\Major_285.wav: \n",
      "Harmonics DataFrame:\n",
      "          id  Label  harmonic_1  harmonic_2  harmonic_3  harmonic_4  \\\n",
      "0    Major_0  Major  258.146341  387.219512  516.292683  645.365854   \n",
      "1    Major_1  Major  387.219512  516.292683  645.365854  774.439024   \n",
      "2   Major_10  Major  258.146341  387.219512  516.292683  731.414634   \n",
      "3  Major_100  Major  301.170732  387.219512  602.341463  774.439024   \n",
      "4  Major_101  Major  301.170732  387.219512  688.390244  946.536585   \n",
      "\n",
      "    harmonic_5   harmonic_6   harmonic_7   harmonic_8  ...  interval_11  \\\n",
      "0   774.439024  1032.585366  1161.658537  1333.756098  ...   215.121951   \n",
      "1   989.560976  1161.658537  1333.756098  1979.121951  ...          NaN   \n",
      "2   946.536585  1118.634146  1333.756098  1419.804878  ...   301.170732   \n",
      "3   946.536585  1118.634146  1376.780488  1548.878049  ...    86.048780   \n",
      "4  1118.634146  1247.707317  1548.878049          NaN  ...          NaN   \n",
      "\n",
      "   interval_12  interval_13  interval_14  interval_15  interval_16  \\\n",
      "0   301.170732   516.292683   516.292683          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2   172.097561          NaN          NaN          NaN          NaN   \n",
      "3   602.341463   559.317073   559.317073          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   interval_17  interval_18  interval_19  interval_20  \n",
      "0          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "\n",
      "Skipped files:\n",
      "C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\dataset\\Audio_Files\\Major\\Major_285.wav\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "harmonics_data = []\n",
    "skipped_files = []  # Initialize list to track skipped files\n",
    "\n",
    "# Extracting harmonics for each file and storing them in a list\n",
    "for index, row in file_data.iterrows():\n",
    "    try:\n",
    "        # Load the audio signal\n",
    "        signal, sr = librosa.load(row['path'], sr=None)\n",
    "        \n",
    "        # Ensure the signal is valid\n",
    "        if signal is None or len(signal) == 0:\n",
    "            print(f\"Warning: Empty or invalid audio signal for {row['path']}\")\n",
    "            skipped_files.append(row['path'])\n",
    "            continue\n",
    "\n",
    "        harmonic_frequencies, harmonic_intervals = find_harmonics(signal=signal, sr=sr)\n",
    "        \n",
    "        if harmonic_frequencies is not None:\n",
    "            harmonics_data.append({\n",
    "                'id': row['id'].replace('.wav', ''),\n",
    "                'Label': row['label'],\n",
    "                'harmonics': harmonic_frequencies,\n",
    "                'intervals': harmonic_intervals\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Warning: No harmonics extracted for {row['path']}\")\n",
    "            skipped_files.append(row['path'])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {row['path']}: {e}\")\n",
    "        skipped_files.append(row['path'])\n",
    "\n",
    "# Ensure there are harmonics extracted\n",
    "if harmonics_data:\n",
    "    # Find the maximum number of harmonic frequencies across all files\n",
    "    max_harmonics = max(len(item['harmonics']) for item in harmonics_data)\n",
    "\n",
    "    # Prepare a list to hold each row's dictionary\n",
    "    harmonics_dict_list = []\n",
    "\n",
    "    for item in harmonics_data:\n",
    "        harmonic_dict = {\n",
    "            'id': item['id'],\n",
    "            'Label': item['Label']\n",
    "        }\n",
    "\n",
    "        # Fill harmonic frequencies, and pad with NaN if there are fewer than max_harmonics\n",
    "        for i in range(max_harmonics):\n",
    "            harmonic_dict[f'harmonic_{i+1}'] = item['harmonics'][i] if i < len(item['harmonics']) else np.nan\n",
    "\n",
    "        # Optionally, add intervals if you want them as well\n",
    "        if item['intervals'] is not None:\n",
    "            for i in range(len(item['intervals'])):\n",
    "                harmonic_dict[f'interval_{i+1}'] = item['intervals'][i]\n",
    "\n",
    "        harmonics_dict_list.append(harmonic_dict)\n",
    "\n",
    "    # Create a new DataFrame from the list of dictionaries\n",
    "    harmonics_df = pd.DataFrame(harmonics_dict_list)\n",
    "    print(\"Harmonics DataFrame:\")\n",
    "    print(harmonics_df.head())\n",
    "else:\n",
    "    print(\"No harmonics were extracted from the files.\")\n",
    "\n",
    "# Print skipped files if any\n",
    "if skipped_files:\n",
    "    print(\"\\nSkipped files:\")\n",
    "    for file in skipped_files:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"\\nNo files were skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34110af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting Mel-spectrogram for C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\dataset\\Audio_Files\\Major\\Major_285.wav: \n",
      "Mel-Spectrogram DataFrame:\n",
      "          id  Label                                    mel_spectrogram\n",
      "0    Major_0  Major  [[-22.629173, -18.381105, -14.328545, -12.8387...\n",
      "1    Major_1  Major  [[-42.334816, -45.12371, -50.84518, -55.982666...\n",
      "2   Major_10  Major  [[-23.402384, -19.154316, -15.101755, -13.6119...\n",
      "3  Major_100  Major  [[-26.984245, -23.075817, -19.678623, -15.0486...\n",
      "4  Major_101  Major  [[-38.758972, -41.832405, -47.83084, -51.69927...\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store Mel-spectrogram data\n",
    "mel_spectrogram_data = []\n",
    "\n",
    "# Extract Mel-spectrograms for each file and store them in a list\n",
    "for index, row in file_data.iterrows():\n",
    "    try:\n",
    "        # Load the original audio signal\n",
    "        signal, sr = librosa.load(row['path'], sr=None)\n",
    "\n",
    "        # Check if the signal is valid\n",
    "        if signal is None or len(signal) == 0:\n",
    "            print(f\"Warning: Empty or invalid audio signal for {row['path']}\")\n",
    "            continue\n",
    "\n",
    "        # Extract Mel-spectrogram using the updated function\n",
    "        mel_spectrogram = extract_mel_spectrogram(signal=signal, sr=sr)\n",
    "\n",
    "        # Store the Mel-spectrogram data\n",
    "        mel_spectrogram_data.append({\n",
    "            'id': row['id'].replace('.wav', ''),\n",
    "            'Label': row['label'],\n",
    "            'mel_spectrogram': mel_spectrogram\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting Mel-spectrogram for {row['path']}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "mel_df = pd.DataFrame(mel_spectrogram_data)\n",
    "\n",
    "# Display the first few rows of the new DataFrame to verify\n",
    "print(\"Mel-Spectrogram DataFrame:\")\n",
    "print(mel_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cf03d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  Label  harmonic_1  harmonic_2  harmonic_3  harmonic_4  \\\n",
      "0    Major_0  Major  258.146341  387.219512  516.292683  645.365854   \n",
      "1    Major_1  Major  387.219512  516.292683  645.365854  774.439024   \n",
      "2   Major_10  Major  258.146341  387.219512  516.292683  731.414634   \n",
      "3  Major_100  Major  301.170732  387.219512  602.341463  774.439024   \n",
      "4  Major_101  Major  301.170732  387.219512  688.390244  946.536585   \n",
      "\n",
      "    harmonic_5   harmonic_6   harmonic_7   harmonic_8  ...  \\\n",
      "0   774.439024  1032.585366  1161.658537  1333.756098  ...   \n",
      "1   989.560976  1161.658537  1333.756098  1979.121951  ...   \n",
      "2   946.536585  1118.634146  1333.756098  1419.804878  ...   \n",
      "3   946.536585  1118.634146  1376.780488  1548.878049  ...   \n",
      "4  1118.634146  1247.707317  1548.878049     0.000000  ...   \n",
      "\n",
      "   harmonic_ratio_16_to_17  harmonic_ratio_16_to_18  harmonic_ratio_16_to_19  \\\n",
      "0                      0.0                      0.0                      0.0   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   harmonic_ratio_16_to_20  harmonic_ratio_17_to_18  harmonic_ratio_17_to_19  \\\n",
      "0                      0.0                      0.0                      0.0   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   harmonic_ratio_17_to_20  harmonic_ratio_18_to_19  harmonic_ratio_18_to_20  \\\n",
      "0                      0.0                      0.0                      0.0   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   harmonic_ratio_19_to_20  \n",
      "0                      0.0  \n",
      "1                      0.0  \n",
      "2                      0.0  \n",
      "3                      0.0  \n",
      "4                      0.0  \n",
      "\n",
      "[5 rows x 253 columns]\n"
     ]
    }
   ],
   "source": [
    "# List to hold the new harmonic ratio columns and their data\n",
    "harmonic_ratio_data = []\n",
    "\n",
    "# Get harmonic columns\n",
    "harmonic_columns = [col for col in harmonics_df.columns if 'harmonic_' in col]\n",
    "\n",
    "# Ensure there are at least 2 harmonic columns to calculate ratios\n",
    "if len(harmonic_columns) > 1:\n",
    "    for i in range(len(harmonic_columns)):\n",
    "        for j in range(i + 1, len(harmonic_columns)):\n",
    "            col_i = harmonic_columns[i]\n",
    "            col_j = harmonic_columns[j]\n",
    "            ratio_col_name = f'harmonic_ratio_{i}_to_{j}'  # Ensure \"harmonic_ratio\" is in the name\n",
    "            \n",
    "            # Calculate the ratio, avoiding division by zero\n",
    "            harmonic_ratio = harmonics_df[col_i] / harmonics_df[col_j]\n",
    "            harmonic_ratio.replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace inf with NaN\n",
    "            \n",
    "            # Append the calculated ratios and column name to the list\n",
    "            harmonic_ratio_data.append(harmonic_ratio.rename(ratio_col_name))\n",
    "    \n",
    "    # Concatenate all harmonic ratio columns at once to the DataFrame\n",
    "    harmonic_ratio_df = pd.concat([harmonics_df] + harmonic_ratio_data, axis=1)\n",
    "\n",
    "    # Fill NaN values with 0 or another appropriate value (depending on your analysis)\n",
    "    harmonic_ratio_df.fillna(0, inplace=True)\n",
    "    \n",
    "    # Display the new DataFrame\n",
    "    print(harmonic_ratio_df.head())\n",
    "else:\n",
    "    print(\"Not enough harmonic columns to compute ratios.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "281242ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Complete DataFrame (with all possible features):\n",
      "          id  Label  chroma_1  chroma_2  chroma_3  chroma_4  chroma_5  \\\n",
      "0    Major_0  Major  0.796852  0.417257  0.299810  0.391450  0.769257   \n",
      "1    Major_1  Major  0.723283  0.452638  0.262528  0.236474  0.472363   \n",
      "2   Major_10  Major  0.371833  0.267660  0.125646  0.144663  0.298086   \n",
      "3  Major_100  Major  0.390774  0.934246  0.763238  0.553007  0.418208   \n",
      "4  Major_101  Major  0.207329  0.403518  0.400692  0.461187  0.456608   \n",
      "\n",
      "   chroma_6  chroma_7  chroma_8  ...  harmonic_ratio_16_to_17  \\\n",
      "0  0.475731  0.173122  0.434240  ...                      0.0   \n",
      "1  0.383091  0.316608  0.407608  ...                      0.0   \n",
      "2  0.462609  0.684176  0.370034  ...                      0.0   \n",
      "3  0.357188  0.244438  0.371424  ...                      0.0   \n",
      "4  0.576159  0.579669  0.570114  ...                      0.0   \n",
      "\n",
      "   harmonic_ratio_16_to_18  harmonic_ratio_16_to_19  harmonic_ratio_16_to_20  \\\n",
      "0                      0.0                      0.0                      0.0   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   harmonic_ratio_17_to_18  harmonic_ratio_17_to_19  harmonic_ratio_17_to_20  \\\n",
      "0                      0.0                      0.0                      0.0   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   harmonic_ratio_18_to_19  harmonic_ratio_18_to_20  harmonic_ratio_19_to_20  \n",
      "0                      0.0                      0.0                      0.0  \n",
      "1                      0.0                      0.0                      0.0  \n",
      "2                      0.0                      0.0                      0.0  \n",
      "3                      0.0                      0.0                      0.0  \n",
      "4                      0.0                      0.0                      0.0  \n",
      "\n",
      "[5 rows x 329 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge features_df, harmonics_df, mel_df, and harmonic_ratio_df\n",
    "raw_complete_df = features_df.merge(harmonics_df, on=['id', 'Label'], how='left')\n",
    "raw_complete_df = raw_complete_df.merge(mel_df, on=['id', 'Label'], how='left')\n",
    "raw_complete_df = raw_complete_df.merge(harmonic_ratio_df, on=['id', 'Label'], how='left')\n",
    "\n",
    "# Display the DataFrame to verify\n",
    "print(\"Raw Complete DataFrame (with all possible features):\")\n",
    "print(raw_complete_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59b9f4d",
   "metadata": {},
   "source": [
    "## Augmenting Data\n",
    "\n",
    "We will augment the audio data using techniques such as time-stretching, pitch-shifting, and adding noise. The augmented data will then have features extracted in the same way as the original data. We will apply these augmentations to our data to create synthetic data - to even the distribution of our classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "506b368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation functions\n",
    "def pitch_shift(signal, sr, n_steps=4):\n",
    "    return librosa.effects.pitch_shift(signal, sr=sr, n_steps=n_steps)\n",
    "\n",
    "def add_noise(signal, noise_factor=0.005):\n",
    "    noise = np.random.randn(len(signal))\n",
    "    return signal + noise_factor * noise\n",
    "\n",
    "def augment_audio(signal, sr):\n",
    "    augmentations = ['time_stretch', 'pitch_shift', 'add_noise']\n",
    "    augmentation = random.choice(augmentations)\n",
    "\n",
    "    if augmentation == 'time_stretch':\n",
    "        return librosa.effects.time_stretch(signal, rate=1.2)\n",
    "    elif augmentation == 'pitch_shift':\n",
    "        return pitch_shift(signal, sr, n_steps=4)\n",
    "    elif augmentation == 'add_noise':\n",
    "        return add_noise(signal)\n",
    "    else:\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1619fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count existing samples in the original dataset\n",
    "original_counts = file_data['label'].value_counts()\n",
    "target_count = 500\n",
    "\n",
    "# Determine how many samples to augment for each class\n",
    "augmented_counts = {}\n",
    "for label, count in original_counts.items():\n",
    "    if count < target_count:\n",
    "        augmented_counts[label] = target_count - count\n",
    "    else:\n",
    "        augmented_counts[label] = 0  # No augmentation needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ef0470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Features DataFrame with all features:\n",
      "              id  Label  chroma_1  chroma_2  chroma_3  chroma_4  chroma_5  \\\n",
      "0    Minor_0_aug  Minor  0.694272  0.445703  0.529096  0.724197  0.410463   \n",
      "1    Minor_1_aug  Minor  0.655989  0.449560  0.266899  0.242286  0.200219   \n",
      "2   Minor_10_aug  Minor  0.753776  0.972707  0.434122  0.300710  0.282845   \n",
      "3  Minor_100_aug  Minor  0.108470  0.074901  0.051982  0.156289  0.388980   \n",
      "4  Minor_101_aug  Minor  0.820669  0.537448  0.254670  0.173032  0.232917   \n",
      "\n",
      "   chroma_6  chroma_7  chroma_8  ...  zero_crossing_rate  \\\n",
      "0  0.087992  0.258958  0.908643  ...            0.044980   \n",
      "1  0.190632  0.423906  0.867719  ...            0.086247   \n",
      "2  0.109526  0.053868  0.224057  ...            0.048661   \n",
      "3  0.226154  0.065551  0.121646  ...            0.026134   \n",
      "4  0.377288  0.276959  0.184213  ...            0.007307   \n",
      "\n",
      "                                     mel_spectrogram  interval_13  \\\n",
      "0  [[-22.204008347185585, -17.895482333864855, -1...          NaN   \n",
      "1  [[-43.56945660550444, -46.43736247346013, -52....          NaN   \n",
      "2  [[-22.843238037054178, -18.997810260784718, -1...   516.292683   \n",
      "3  [[-21.794443, -16.598566, -14.688595, -16.7609...          NaN   \n",
      "4  [[-39.147316, -42.57921, -47.186386, -50.22955...          NaN   \n",
      "\n",
      "   interval_14  interval_15  interval_16  interval_17  interval_18  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   interval_19  interval_20  \n",
      "0          NaN          NaN  \n",
      "1          NaN          NaN  \n",
      "2          NaN          NaN  \n",
      "3          NaN          NaN  \n",
      "4          NaN          NaN  \n",
      "\n",
      "[5 rows x 78 columns]\n"
     ]
    }
   ],
   "source": [
    "# Augmentation and Feature Extraction Workflow (including harmonics and mel-spectrogram)\n",
    "augmented_data = []\n",
    "\n",
    "# Track how many augmentations done for each class\n",
    "augmentation_tracker = {label: 0 for label in augmented_counts.keys()}\n",
    "\n",
    "for index, row in file_data.iterrows():\n",
    "    try:\n",
    "        # Check if we need to augment this class\n",
    "        if augmentation_tracker[row['label']] >= augmented_counts[row['label']]:\n",
    "            continue  # Skip if we've reached the target augmentation\n",
    "\n",
    "        # Load the original audio signal\n",
    "        signal, sr = librosa.load(row['path'], sr=None)\n",
    "\n",
    "        # Ensure the signal is valid before proceeding\n",
    "        if signal is None or len(signal) == 0:\n",
    "            print(f\"Warning: Empty or invalid audio signal for {row['path']}\")\n",
    "            continue\n",
    "\n",
    "        # Apply augmentation\n",
    "        augmented_signal = augment_audio(signal, sr)\n",
    "\n",
    "        # Ensure the augmented signal is valid\n",
    "        if augmented_signal is None or not isinstance(augmented_signal, np.ndarray):\n",
    "            print(f\"Warning: Augmented signal is not valid for {row['path']}\")\n",
    "            continue\n",
    "\n",
    "        # Extract features from the augmented signal\n",
    "        features = extract_audio_features(signal=augmented_signal, sr=sr)\n",
    "        harmonics, intervals = find_harmonics(signal=augmented_signal, sr=sr)\n",
    "        mel_spectrogram = extract_mel_spectrogram(signal=augmented_signal, sr=sr)\n",
    "\n",
    "        # Check if all features were successfully extracted\n",
    "        if features is None or harmonics is None or mel_spectrogram is None:\n",
    "            print(f\"Warning: Some features were None for {row['path']}\")\n",
    "            continue\n",
    "\n",
    "        # Append the features to the augmented data list\n",
    "        augmented_data.append({\n",
    "            'id': row['id'].replace('.wav', '') + '_aug',\n",
    "            'label': row['label'],\n",
    "            'chroma': features['chroma'],\n",
    "            'mfcc': features['mfcc'],\n",
    "            'spectral_centroid': features['spectral_centroid'],\n",
    "            'zero_crossing_rate': features['zero_crossing_rate'],\n",
    "            'harmonics': harmonics,\n",
    "            'intervals': intervals,\n",
    "            'mel_spectrogram': mel_spectrogram\n",
    "        })\n",
    "\n",
    "        # Increment the augmentation count for the class\n",
    "        augmentation_tracker[row['label']] += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error augmenting and extracting features from {row['path']}: {e}\")\n",
    "\n",
    "# Preparing DataFrame for the augmented data\n",
    "augmented_feature_dict_list = []\n",
    "n_chroma = 12\n",
    "n_mfcc = 20\n",
    "max_harmonics = max([len(item['harmonics']) for item in augmented_data if item['harmonics'] is not None], default=0)\n",
    "\n",
    "for item in augmented_data:\n",
    "    feature_dict = {\n",
    "        'id': item['id'],\n",
    "        'Label': item['label']\n",
    "    }\n",
    "    \n",
    "    # Store chroma features\n",
    "    for i in range(n_chroma):\n",
    "        feature_dict[f'chroma_{i+1}'] = item['chroma'][i] if item['chroma'] is not None and i < len(item['chroma']) else np.nan\n",
    "    \n",
    "    # Store MFCC features\n",
    "    for i in range(n_mfcc):\n",
    "        feature_dict[f'mfcc_{i+1}'] = item['mfcc'][i] if item['mfcc'] is not None and i < len(item['mfcc']) else np.nan\n",
    "    \n",
    "    # Store harmonic features\n",
    "    for i in range(max_harmonics):\n",
    "        feature_dict[f'harmonic_{i+1}'] = item['harmonics'][i] if item['harmonics'] is not None and i < len(item['harmonics']) else np.nan\n",
    "    \n",
    "    # Store interval features\n",
    "    if item['intervals'] is not None:\n",
    "        for i in range(len(item['intervals'])):\n",
    "            feature_dict[f'interval_{i+1}'] = item['intervals'][i]\n",
    "\n",
    "    # Store other features\n",
    "    feature_dict['spectral_centroid'] = item['spectral_centroid'] if item['spectral_centroid'] is not None else np.nan\n",
    "    feature_dict['zero_crossing_rate'] = item['zero_crossing_rate'] if item['zero_crossing_rate'] is not None else np.nan\n",
    "    feature_dict['mel_spectrogram'] = item['mel_spectrogram'] if item['mel_spectrogram'] is not None else np.nan\n",
    "\n",
    "    augmented_feature_dict_list.append(feature_dict)\n",
    "\n",
    "# Create a DataFrame for augmented features\n",
    "augmented_features_df = pd.DataFrame(augmented_feature_dict_list)\n",
    "\n",
    "# Display the DataFrame to verify results\n",
    "print(\"Augmented Features DataFrame with all features:\")\n",
    "print(augmented_features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03452b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Harmonic Ratios DataFrame:\n",
      "              id  Label  chroma_1  chroma_2  chroma_3  chroma_4  chroma_5  \\\n",
      "0    Minor_0_aug  Minor  0.694272  0.445703  0.529096  0.724197  0.410463   \n",
      "1    Minor_1_aug  Minor  0.655989  0.449560  0.266899  0.242286  0.200219   \n",
      "2   Minor_10_aug  Minor  0.753776  0.972707  0.434122  0.300710  0.282845   \n",
      "3  Minor_100_aug  Minor  0.108470  0.074901  0.051982  0.156289  0.388980   \n",
      "4  Minor_101_aug  Minor  0.820669  0.537448  0.254670  0.173032  0.232917   \n",
      "\n",
      "   chroma_6  chroma_7  chroma_8  ...  harmonic_ratio_16_to_17  \\\n",
      "0  0.087992  0.258958  0.908643  ...                      0.0   \n",
      "1  0.190632  0.423906  0.867719  ...                      0.0   \n",
      "2  0.109526  0.053868  0.224057  ...                      0.0   \n",
      "3  0.226154  0.065551  0.121646  ...                      0.0   \n",
      "4  0.377288  0.276959  0.184213  ...                      0.0   \n",
      "\n",
      "   harmonic_ratio_16_to_18  harmonic_ratio_16_to_19  harmonic_ratio_16_to_20  \\\n",
      "0                      0.0                      0.0                      0.0   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   harmonic_ratio_17_to_18  harmonic_ratio_17_to_19  harmonic_ratio_17_to_20  \\\n",
      "0                      0.0                      0.0                      0.0   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   harmonic_ratio_18_to_19  harmonic_ratio_18_to_20  harmonic_ratio_19_to_20  \n",
      "0                      0.0                      0.0                      0.0  \n",
      "1                      0.0                      0.0                      0.0  \n",
      "2                      0.0                      0.0                      0.0  \n",
      "3                      0.0                      0.0                      0.0  \n",
      "4                      0.0                      0.0                      0.0  \n",
      "\n",
      "[5 rows x 288 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate Harmonic Ratios for Augmented Data\n",
    "augmented_harmonic_ratio_data = []\n",
    "\n",
    "# Get harmonic columns from augmented_features_df\n",
    "augmented_harmonic_columns = [col for col in augmented_features_df.columns if 'harmonic_' in col]\n",
    "\n",
    "# Ensure there are at least 2 harmonic columns to calculate ratios\n",
    "if len(augmented_harmonic_columns) > 1:\n",
    "    for i in range(len(augmented_harmonic_columns)):\n",
    "        for j in range(i + 1, len(augmented_harmonic_columns)):\n",
    "            col_i = augmented_harmonic_columns[i]\n",
    "            col_j = augmented_harmonic_columns[j]\n",
    "            ratio_col_name = f'harmonic_ratio_{i}_to_{j}'  # Ensure \"harmonic_ratio\" is in the name\n",
    "            \n",
    "            # Calculate the ratio, avoiding division by zero\n",
    "            harmonic_ratio = augmented_features_df[col_i] / augmented_features_df[col_j]\n",
    "            harmonic_ratio.replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace inf with NaN\n",
    "            \n",
    "            # Append the calculated ratios and column name to the list\n",
    "            augmented_harmonic_ratio_data.append(harmonic_ratio.rename(ratio_col_name))\n",
    "    \n",
    "    # Concatenate all harmonic ratio columns at once to the DataFrame\n",
    "    augmented_harmonic_ratio_df = pd.concat([augmented_features_df] + augmented_harmonic_ratio_data, axis=1)\n",
    "\n",
    "    # Fill NaN values with 0 or another appropriate value (depending on your analysis)\n",
    "    augmented_harmonic_ratio_df.fillna(0, inplace=True)\n",
    "    \n",
    "    # Display the new DataFrame\n",
    "    print(\"Augmented Harmonic Ratios DataFrame:\")\n",
    "    print(augmented_harmonic_ratio_df.head())\n",
    "else:\n",
    "    print(\"Not enough harmonic columns in augmented data to compute ratios.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fe23deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_complete_df (cleaned, with all possible features):\n",
      "              id  Label  chroma_1  chroma_2  chroma_3  chroma_4  chroma_5  \\\n",
      "0    Minor_0_aug  Minor  0.694272  0.445703  0.529096  0.724197  0.410463   \n",
      "1    Minor_1_aug  Minor  0.655989  0.449560  0.266899  0.242286  0.200219   \n",
      "2   Minor_10_aug  Minor  0.753776  0.972707  0.434122  0.300710  0.282845   \n",
      "3  Minor_100_aug  Minor  0.108470  0.074901  0.051982  0.156289  0.388980   \n",
      "4  Minor_101_aug  Minor  0.820669  0.537448  0.254670  0.173032  0.232917   \n",
      "\n",
      "   chroma_6  chroma_7  chroma_8  ...  harmonic_ratio_16_to_17  \\\n",
      "0  0.087992  0.258958  0.908643  ...                      0.0   \n",
      "1  0.190632  0.423906  0.867719  ...                      0.0   \n",
      "2  0.109526  0.053868  0.224057  ...                      0.0   \n",
      "3  0.226154  0.065551  0.121646  ...                      0.0   \n",
      "4  0.377288  0.276959  0.184213  ...                      0.0   \n",
      "\n",
      "   harmonic_ratio_16_to_18  harmonic_ratio_16_to_19  harmonic_ratio_16_to_20  \\\n",
      "0                      0.0                      0.0                      0.0   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   harmonic_ratio_17_to_18  harmonic_ratio_17_to_19  harmonic_ratio_17_to_20  \\\n",
      "0                      0.0                      0.0                      0.0   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   harmonic_ratio_18_to_19  harmonic_ratio_18_to_20  harmonic_ratio_19_to_20  \n",
      "0                      0.0                      0.0                      0.0  \n",
      "1                      0.0                      0.0                      0.0  \n",
      "2                      0.0                      0.0                      0.0  \n",
      "3                      0.0                      0.0                      0.0  \n",
      "4                      0.0                      0.0                      0.0  \n",
      "\n",
      "[5 rows x 364 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge augmented_features_df and augmented_harmonic_ratio_df\n",
    "augmented_complete_df = augmented_features_df.merge(augmented_harmonic_ratio_df, on=['id', 'Label'], how='left')\n",
    "\n",
    "# Remove the '_x' suffix from the chroma and other feature columns by renaming them\n",
    "augmented_complete_df.columns = augmented_complete_df.columns.str.replace('_x', '')\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"augmented_complete_df (cleaned, with all possible features):\")\n",
    "print(augmented_complete_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a3a49",
   "metadata": {},
   "source": [
    "## Combining Dataframes\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
