{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9689b7aa",
   "metadata": {},
   "source": [
    "# Musical Chord Classification\n",
    "\n",
    "## Business Understanding\n",
    "\n",
    "- [ ] Introduction explains the real-world problem the project aims to solve\n",
    "- [ ] Introduction identifies stakeholders who could use the project and how they would use it\n",
    "- [ ] Conclusion summarizes implications of the project for the real-world problem and stakeholders \n",
    "\n",
    "\n",
    "### Introduction:\n",
    "\n",
    "This project addresses the challenge of accurately identifying musical chords as either major or minor using audio input. Manual chord transcription can be time-consuming and requires a solid grasp of music theory. By leveraging machine learning and audio processing techniques, this tool automates chord classification, providing real-time results that are valuable to musicians, music producers, and educators.\n",
    "\n",
    "### Stakeholders:\n",
    "\n",
    "- **Musicians** can use the tool to quickly identify chords during practice or live performances, enhancing learning and improvisation.\n",
    "- **Music Producers** benefit from real-time chord analysis, streamlining the composition and arrangement process.\n",
    "- **Educators** gain an interactive way to teach chord progressions and musical theory, helping students grasp harmonic relationships more effectively.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "The model achieved 98% accuracy by utilizing data augmentation to balance the dataset, originally skewed towards major chords (502 major, 357 minor). Augmenting 143 minor chord samples created a more even distribution, improving classification performance. This tool has the potential to save time and improve the workflow for musicians, producers, and educators by automating chord recognition, making it more accessible and efficient.\n",
    "\n",
    "\n",
    "### Tools and Methodologies used:\n",
    "- Audio feature extraction with `librosa`\n",
    "- Data manipulation with `numpy`, `pandas`\n",
    "- Visualization with `matplotlib`, `seaborn`\n",
    "- Machine Learning models with `scikit-learn` and Deep Learning with `tensorflow/keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d93a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Audio feature extraction\n",
    "import librosa\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Kaggle API for dataset download\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Data visualization\n",
    "import warnings\n",
    "\n",
    "# Machine learning models and utilities\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ignore warnings from specific modules\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"librosa\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"librosa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d118a6b",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "- [ ] Describe the data sources and explain why the data are suitable for the project\n",
    "- [ ] Present the size of the dataset and descriptive statistics for all features used in the analysis\n",
    "- [ ] Justify the inclusion of features based on their properties and relevance for the project\n",
    "- [ ] Identify any limitations of the data that have implications for the project\n",
    "\n",
    "\n",
    "\n",
    "The dataset used for this project is the [Musical Instrument Chord Classification (Audio)](https://www.kaggle.com/datasets/deepcontractor/musical-instrument-chord-classification) dataset from Kaggle. It consists of .wav audio files, containing major and minor chords played on guitar and piano. Since the dataset is readily available, it eliminates the need for manual data collection. The clear distinction between major and minor chords makes it highly suitable for this classification task.\n",
    "\n",
    "### Dataset Size and Features:\n",
    "\n",
    "#### Size: \n",
    "> The dataset contains 859 audio samplesâ€”502 major chords and 357 minor chords. To balance the dataset, we applied augmentation, adding 143 minor chord samples, resulting in 500 samples for each class.\n",
    "\n",
    "#### Features: \n",
    "> While earlier iterations explored features such as Mel-frequency cepstral coefficients (MFCCs), Chroma, Spectral centroid, zero-crossing rate, and Mel-spectrograms, the final model focuses exclusively on harmonic content. Specifically, harmonic ratios were extracted and analyzed to capture the major/minor third distinction. These selected harmonic ratios were identified both visually and through statistical analysis, with a p-value < 0.05, indicating their statistical significance in distinguishing between major and minor chords.\n",
    "\n",
    "The experimental exploration of other features and iterations can be found in the accompanying `workbook.ipynb`, but the final model is built solely on harmonic extraction and analysis.\n",
    "\n",
    "### Justification of Features:\n",
    "\n",
    "Harmonic ratios directly reflect the intervals between notes in a chord, which is the key distinction between major and minor chords. The visually and statistically significant harmonic ratios make this approach highly relevant for the classification task, focusing precisely on the differences between the two chord types.\n",
    "\n",
    "#### Data Limitations:\n",
    "\n",
    "One limitation of the dataset is its restriction to two instruments: guitar and piano. This limits the model's applicability to other instruments, as the harmonic content of chords can vary with timbre. Additionally, the dataset lacks variation in dynamics and playing styles, which might affect chord recognition in diverse musical contexts. Therefore, while the model performs well on this dataset, its generalization to other instruments or more complex real-world music may be limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46151677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if replicating project\n",
    "# !pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a436dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_kaggle_api(api_config_path: str = 'kaggle.json'):\n",
    "    \"\"\"\n",
    "    Authenticate Kaggle API to allow dataset download.\n",
    "\n",
    "    Parameters:\n",
    "    api_config_path (str): Path to Kaggle API configuration file.\n",
    "    \"\"\"\n",
    "    with open(api_config_path, 'r') as f:\n",
    "        kaggle_config = json.load(f)\n",
    "\n",
    "    os.environ['KAGGLE_USERNAME'] = kaggle_config['username']\n",
    "    os.environ['KAGGLE_KEY'] = kaggle_config['key']\n",
    "\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    return api\n",
    "\n",
    "# Initialize Kaggle API and download dataset\n",
    "def download_dataset(api, dataset_name: str, destination_dir: str):\n",
    "    \"\"\"\n",
    "    Download and extract the dataset using Kaggle API.\n",
    "\n",
    "    Parameters:\n",
    "    api: KaggleApi instance.\n",
    "    dataset_name (str): Name of the dataset to download.\n",
    "    destination_dir (str): Directory to save the dataset.\n",
    "    \"\"\"\n",
    "    os.makedirs(destination_dir, exist_ok=True)\n",
    "    api.dataset_download_files(dataset_name, path=destination_dir, unzip=True)\n",
    "    print(\"Dataset downloaded and extracted to:\", destination_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f514249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/deepcontractor/musical-instrument-chord-classification\n",
      "Dataset downloaded and extracted to: C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\dataset\n"
     ]
    }
   ],
   "source": [
    "# Authenticate and download Kaggle dataset\n",
    "api = authenticate_kaggle_api()\n",
    "dataset_dir = os.path.join(os.getcwd(), 'dataset')\n",
    "download_dataset(api, 'deepcontractor/musical-instrument-chord-classification', dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af07149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_file_details(base_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load details of audio files from specified directory.\n",
    "\n",
    "    Parameters:\n",
    "    base_dir (str): Base directory containing audio files.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing file paths, ids, and labels.\n",
    "    \"\"\"\n",
    "    file_details = []\n",
    "    for category in ['Major', 'Minor']:\n",
    "        category_dir = os.path.join(base_dir, category)\n",
    "        for filename in os.listdir(category_dir):\n",
    "            if filename.endswith('.wav'):\n",
    "                file_details.append({'path': os.path.join(category_dir, filename), 'id': filename, 'label': category})\n",
    "    return pd.DataFrame(file_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9c9e23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                path             id  label\n",
      "0  C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\da...    Major_0.wav  Major\n",
      "1  C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\da...    Major_1.wav  Major\n",
      "2  C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\da...   Major_10.wav  Major\n",
      "3  C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\da...  Major_100.wav  Major\n",
      "4  C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\da...  Major_101.wav  Major\n"
     ]
    }
   ],
   "source": [
    "base_dir = os.path.join(dataset_dir, 'Audio_Files')\n",
    "file_data = load_audio_file_details(base_dir)\n",
    "print(file_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc01132",
   "metadata": {},
   "source": [
    "## Music and Math\n",
    "\n",
    "Each musical note corresponds to a fundamental frequency - the lowest frequency of a note that is musically pleasing. This frequency is what characterizes the note, which is represented by letters ['A', 'B', 'C', 'D', 'E', 'F', 'G']. \n",
    "\n",
    "#### Frequency:\n",
    "\n",
    "The frequency \\( f \\) of a note can be calculated with the following formula:\n",
    "\n",
    "$$ f = f_0 \\times 2^{\\frac{n}{12}} $$\n",
    "\n",
    "Where:\n",
    "- `f_0` is the frequency of a reference note (usually the note **A4**, which is **440 Hz**).\n",
    "- `n` is the number of half-steps away from the reference note. Positive values of `n` indicate higher notes, while negative values indicate lower notes.\n",
    "\n",
    "The standard practice in determining the closest note to a given frequency generally involves finding which standard note frequency it's nearest to.\n",
    "\n",
    "#### Harmonics\n",
    "\n",
    "A single note played on an instrument does not produce just one frequency. For example, playing an 'A' at 220 Hz will generate additional frequencies at 440 Hz, 660 Hz, 880 Hz, 1100 Hz, and so on. According to this [Music Note Frequency Chart](https://mixbutton.com/mixing-articles/music-note-to-frequency-chart/) the frequencies 220, 440, and 880 Hz correspond to the musical notes A3, A4, and A5, respectively. These notes are all 'A' notes, each one octave apart. The lowest harmonic, known as the fundamental frequency, determines the perceived pitch of the sound.\n",
    "\n",
    "> In standard musical pitch, A4, or the fourth octave 'A', is tuned to 440 Hz.\n",
    "\n",
    "Interestingly, the frequency 1100 Hz falls between the frequencies for B5 (987.77 Hz) and C6 (1046.50 Hz). Calculating the midpoint between these two frequencies gives:\n",
    "\n",
    "$$\n",
    "\\text{Midpoint} = \\frac{987.77 \\, \\text{Hz} + 1046.50 \\, \\text{Hz}}{2} = 1017.135 \\, \\text{Hz}\n",
    "$$\n",
    "\n",
    "Since 1100 Hz is closer to 1046.50 Hz than to 987.77 Hz, it would be classified closer to C6 in standard musical pitch, though it is somewhat sharper than a typical B5. This illustrates how harmonics work in physical instruments, where playing a fundamental note also produces these higher frequencies, contributing to the richness of the instrument's sound.\n",
    "\n",
    "#### Chords\n",
    "\n",
    "A chord represents a combination of several notes played simultaneously, resulting in a harmonious sound. This harmony is achieved through the specific relationship of the frequencies of the notes within the chord. For instance, a simple major chord is composed of the root note, a major third above the root, and a perfect fifth above the root, creating a full and bright sound typically associated with major chords.\n",
    "\n",
    "Minor chords, on the other hand, are formed by the root note, a minor third above the root, and a perfect fifth above the root, delivering a more melancholic or somber tone compared to major chords.\n",
    "\n",
    "In addition to major and minor chords, two other common types are diminished and augmented chords. A diminished chord is made up of the root note, a minor third, and a diminished fifth, giving it a tense and unstable sound. An augmented chord consists of the root note, a major third, and an augmented fifth, which creates a sense of suspense or unresolved tension.\n",
    "\n",
    "#### FourierTransforms\n",
    "\n",
    "A Fourier transform is a powerful mathematical tool that transforms a signal from its original domain (often time or space) into a frequency domain. This transformation allows us to dissect complex signals and understand how different frequencies contribute to the overall signal. Essentially, it breaks down a wave-like signal into its individual components, highlighting the frequencies that are present.\n",
    "\n",
    "Why does this help us? Well, by using a Fourier transform, we can analyze various aspects of signals that are not immediately apparent in the time domain. For example, in music production, it helps us identify the specific frequencies that make up a sound, which is crucial for tasks like mixing, mastering, or even sound design. This analysis provides insights into the pitch, tone, and timbre of sounds, helping audio engineers and musicians make informed decisions to enhance musical pieces.\n",
    "\n",
    "In essence, the Fourier transform is a bridge between the time domain and the frequency domain, providing a comprehensive look at the frequencies that influence a signal. This capability makes it an indispensable tool in fields ranging from audio processing to telecommunications and beyond.\n",
    "\n",
    "Using a frequency chart to analyze these chords would reveal a complex spectrum due to the concurrent presence of multiple notes. Each note in a chord contributes its fundamental frequency along with its harmonics, leading to a dense array of spikes on the chart. This complex interplay of frequencies helps to understand why chords have their distinctive sounds and emotional impacts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e26cc0",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "- [ ] Instructions or code needed to get and prepare the raw data for analysis\n",
    "- [ ] Code comments and text to explain what your data preparation code does\n",
    "- [ ] Valid justifications for why the steps you took are appropriate for the problem you are solving\n",
    "\n",
    "The distinction between major and minor chords lies in the intervals between their constituent notes, particularly the major and minor third intervals. By analyzing the harmonics of audio signals, we can accurately capture these relationships, as the harmonics are directly tied to the frequencies that define the chord's structure.\n",
    "\n",
    "The extraction functions were designed to isolate and analyze these harmonics using Fourier transforms, which break down the audio signal into its individual frequency components. This allows us to identify not just the fundamental frequencies, but also their harmonic overtones, giving a clear picture of the harmonic intervals that characterize each chord. The harmonic intervals and ratios extracted through these functions provide precise and relevant data for distinguishing between major and minor chords, making this approach both targeted and effective for the problem at hand.\n",
    "\n",
    "By using only the harmonic content for the final model, we focused on the core features essential to chord classification, ensuring both the relevance and efficiency of the feature extraction process.\n",
    "\n",
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "273bebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_harmonics(signal=None, sr=22050, n_fft=2048):\n",
    "    try:\n",
    "        if signal is None or len(signal) == 0:\n",
    "            raise ValueError(\"No audio signal provided.\")\n",
    "\n",
    "        S = np.abs(librosa.stft(signal, n_fft=n_fft))\n",
    "        magnitude = np.mean(S, axis=1)\n",
    "        frequency = np.fft.fftfreq(len(magnitude), 1/sr)\n",
    "        positive_freq_idxs = np.where(frequency >= 0)\n",
    "        positive_freqs = frequency[positive_freq_idxs]\n",
    "        positive_magnitude = magnitude[positive_freq_idxs]\n",
    "\n",
    "        peaks, _ = find_peaks(positive_magnitude, height=np.max(positive_magnitude) * 0.1)\n",
    "        harmonic_frequencies = positive_freqs[peaks]\n",
    "        harmonic_intervals = np.diff(harmonic_frequencies) if len(harmonic_frequencies) > 1 else []\n",
    "\n",
    "        return harmonic_frequencies, harmonic_intervals\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing harmonics for augmented signal: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "608545c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_signal(path, sr=None):\n",
    "    try:\n",
    "        signal, sr = librosa.load(path, sr=sr)\n",
    "        return signal, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio from {path}: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9438c74",
   "metadata": {},
   "source": [
    "#### Running Feature Extraction on Origional Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff8320b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_signals(data, feature_toggles):\n",
    "    feature_dict_list = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        try:\n",
    "            # Extract audio signal\n",
    "            signal, sr = extract_audio_signal(row['path'])\n",
    "            if signal is None:\n",
    "                continue  # Skip if signal is not available\n",
    "\n",
    "            # Initialize the feature dictionary with basic info\n",
    "            feature_dict = {'id': row['id'], 'Label': row['label'], 'audio_signal': signal}\n",
    "\n",
    "            # Extract features based on toggles\n",
    "            if feature_toggles.get('chroma', False):\n",
    "                feature_dict.update({'chroma': extract_audio_features(signal, sr)['chroma']})\n",
    "            if feature_toggles.get('mfcc', False):\n",
    "                feature_dict.update({'mfcc': extract_audio_features(signal, sr)['mfcc']})\n",
    "            if feature_toggles.get('spectral_centroid', False):\n",
    "                feature_dict['spectral_centroid'] = extract_audio_features(signal, sr)['spectral_centroid']\n",
    "            if feature_toggles.get('zero_crossing_rate', False):\n",
    "                feature_dict['zero_crossing_rate'] = extract_audio_features(signal, sr)['zero_crossing_rate']\n",
    "            if feature_toggles.get('harmonics', False):\n",
    "                harmonics, intervals = find_harmonics(signal, sr)\n",
    "                feature_dict['harmonics'] = harmonics\n",
    "                feature_dict['intervals'] = intervals\n",
    "            if feature_toggles.get('mel_spectrogram', False):\n",
    "                mel_spectrogram = extract_mel_spectrogram(signal, sr)\n",
    "                feature_dict['mel_spectrogram'] = mel_spectrogram.flatten()\n",
    "\n",
    "            # Extract comprehensive harmonic ratios for major/minor classification\n",
    "            if feature_toggles.get('harmonic_ratios', False):\n",
    "                harmonic_ratios = extract_comprehensive_harmonic_ratios(signal, sr)\n",
    "                feature_dict.update(harmonic_ratios)\n",
    "\n",
    "            # Append the dictionary to the list\n",
    "            feature_dict_list.append(feature_dict)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {row['path']}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(feature_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "872d5382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-eb235a571815>:3: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  signal, sr = librosa.load(path, sr=sr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading audio from C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\dataset\\Audio_Files\\Major\\Major_285.wav: \n",
      "Extracted Features DataFrame:\n",
      "          id  Label                                       audio_signal  \\\n",
      "0    Major_0  major  [-0.004333496, -0.0058898926, -0.0048217773, -...   \n",
      "1    Major_1  major  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2   Major_10  major  [-0.004333496, -0.0058898926, -0.0048217773, -...   \n",
      "3  Major_100  major  [-0.0062561035, -0.008087158, -0.007171631, -0...   \n",
      "4  Major_101  major  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                           harmonics  \\\n",
      "0  [258.1463414634146, 387.2195121951219, 516.292...   \n",
      "1  [387.2195121951219, 516.2926829268292, 645.365...   \n",
      "2  [258.1463414634146, 387.2195121951219, 516.292...   \n",
      "3  [301.1707317073171, 387.2195121951219, 602.341...   \n",
      "4  [301.1707317073171, 387.2195121951219, 688.390...   \n",
      "\n",
      "                                           intervals  \n",
      "0  [129.0731707317073, 129.0731707317073, 129.073...  \n",
      "1  [129.0731707317073, 129.07317073170736, 129.07...  \n",
      "2  [129.0731707317073, 129.0731707317073, 215.121...  \n",
      "3  [86.04878048780483, 215.12195121951225, 172.09...  \n",
      "4  [86.04878048780483, 301.1707317073171, 258.146...  \n"
     ]
    }
   ],
   "source": [
    "# Feature Toggles\n",
    "feature_toggles = {\n",
    "    'chroma': False,\n",
    "    'mfcc': False,\n",
    "    'spectral_centroid': False,\n",
    "    'zero_crossing_rate': False,\n",
    "    'harmonics': True,\n",
    "    'mel_spectrogram': False,\n",
    "}\n",
    "\n",
    "# Extract Features for All Data\n",
    "raw_features_df = extract_features_from_signals(file_data, feature_toggles)\n",
    "raw_features_df['id'] = raw_features_df['id'].str.replace('.wav', '', regex=False)\n",
    "raw_features_df['Label'] = raw_features_df['Label'].str.lower()\n",
    "\n",
    "# Display Resulting DataFrame\n",
    "print(\"Extracted Features DataFrame:\")\n",
    "print(raw_features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c88c94f",
   "metadata": {},
   "source": [
    "## Augmenting Data\n",
    "\n",
    "We will augment the audio data using techniques such as time-stretching, pitch-shifting, and adding noise. The augmented data will then have features extracted in the same way as the original data. We will apply these augmentations to our data to create synthetic data - to even the distribution of our classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "737a1beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation functions\n",
    "def pitch_shift(signal, sr, n_steps=4):\n",
    "    return librosa.effects.pitch_shift(signal, sr=sr, n_steps=n_steps)\n",
    "\n",
    "def add_noise(signal, noise_factor=0.005):\n",
    "    noise = np.random.randn(len(signal))\n",
    "    return signal + noise_factor * noise\n",
    "\n",
    "def augment_audio(signal, sr):\n",
    "    augmentations = ['time_stretch', 'pitch_shift', 'add_noise']\n",
    "    augmentation = random.choice(augmentations)\n",
    "\n",
    "    if augmentation == 'time_stretch':\n",
    "        return librosa.effects.time_stretch(signal, rate=1.2)\n",
    "    elif augmentation == 'pitch_shift':\n",
    "        return pitch_shift(signal, sr, n_steps=4)\n",
    "    elif augmentation == 'add_noise':\n",
    "        return add_noise(signal)\n",
    "    else:\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8658e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count existing samples in the original dataset\n",
    "original_counts = file_data['label'].value_counts()\n",
    "target_count = 500\n",
    "\n",
    "# Determine how many samples to augment for each class\n",
    "augmented_counts = {label: target_count - count if count < target_count else 0 for label, count in original_counts.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "402878d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_signals(data, feature_toggles):\n",
    "    \"\"\"\n",
    "    Extract features from audio signals in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): DataFrame containing audio file details.\n",
    "    feature_toggles (dict): Dictionary specifying which features to extract.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing extracted features.\n",
    "    \"\"\"\n",
    "    feature_dict_list = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        try:\n",
    "            # Extract audio signal\n",
    "            signal, sr = extract_audio_signal(row['path'])\n",
    "            if signal is None:\n",
    "                continue  # Skip to next if signal is not available\n",
    "\n",
    "            # Initialize the feature dictionary with basic info\n",
    "            feature_dict = {'id': row['id'], 'Label': row['label'], 'audio_signal': signal}\n",
    "\n",
    "            # Extract features based on toggles\n",
    "            audio_features = extract_audio_features(signal, sr)\n",
    "            if feature_toggles.get('chroma', False):\n",
    "                chroma_features = audio_features.get('chroma')\n",
    "                if chroma_features is not None:\n",
    "                    feature_dict['chroma'] = chroma_features\n",
    "            \n",
    "            if feature_toggles.get('mfcc', False):\n",
    "                mfcc_features = audio_features.get('mfcc')\n",
    "                if mfcc_features is not None:\n",
    "                    feature_dict['mfcc'] = mfcc_features\n",
    "\n",
    "            if feature_toggles.get('spectral_centroid', False):\n",
    "                spectral_centroid = audio_features.get('spectral_centroid')\n",
    "                if spectral_centroid is not None:\n",
    "                    feature_dict['spectral_centroid'] = spectral_centroid\n",
    "\n",
    "            if feature_toggles.get('zero_crossing_rate', False):\n",
    "                zero_crossing_rate = audio_features.get('zero_crossing_rate')\n",
    "                if zero_crossing_rate is not None:\n",
    "                    feature_dict['zero_crossing_rate'] = zero_crossing_rate\n",
    "\n",
    "            if feature_toggles.get('harmonics', False):\n",
    "                harmonics, intervals = find_harmonics(signal, sr)\n",
    "                if harmonics is not None:\n",
    "                    feature_dict['harmonics'] = harmonics\n",
    "                if intervals is not None:\n",
    "                    feature_dict['intervals'] = intervals\n",
    "\n",
    "            if feature_toggles.get('mel_spectrogram', False):\n",
    "                mel_spectrogram = extract_mel_spectrogram(signal, sr)\n",
    "                if mel_spectrogram is not None:\n",
    "                    feature_dict['mel_spectrogram'] = mel_spectrogram.flatten()\n",
    "\n",
    "            # Append the dictionary to the list\n",
    "            feature_dict_list.append(feature_dict)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {row['path']}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(feature_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b34d1e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-eb235a571815>:3: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  signal, sr = librosa.load(path, sr=sr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading audio from C:\\Users\\Nik\\Desktop\\code\\Flatiron\\capstone\\dataset\\Audio_Files\\Major\\Major_285.wav: \n",
      "Extracted Features DataFrame (Cleaned Augmented Data):\n",
      "          id  Label                                       audio_signal  \\\n",
      "0    Major_0  major  [-0.004333496, -0.0058898926, -0.0048217773, -...   \n",
      "1    Major_1  major  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2   Major_10  major  [-0.004333496, -0.0058898926, -0.0048217773, -...   \n",
      "3  Major_100  major  [-0.0062561035, -0.008087158, -0.007171631, -0...   \n",
      "4  Major_101  major  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                           harmonics  \\\n",
      "0  [258.1463414634146, 387.2195121951219, 516.292...   \n",
      "1  [387.2195121951219, 516.2926829268292, 645.365...   \n",
      "2  [258.1463414634146, 387.2195121951219, 516.292...   \n",
      "3  [301.1707317073171, 387.2195121951219, 602.341...   \n",
      "4  [301.1707317073171, 387.2195121951219, 688.390...   \n",
      "\n",
      "                                           intervals  \n",
      "0  [129.0731707317073, 129.0731707317073, 129.073...  \n",
      "1  [129.0731707317073, 129.07317073170736, 129.07...  \n",
      "2  [129.0731707317073, 129.0731707317073, 215.121...  \n",
      "3  [86.04878048780483, 215.12195121951225, 172.09...  \n",
      "4  [86.04878048780483, 301.1707317073171, 258.146...  \n"
     ]
    }
   ],
   "source": [
    "# Feature Toggles for Augmented Data\n",
    "feature_toggles = {\n",
    "    'chroma': False,\n",
    "    'mfcc': False,\n",
    "    'spectral_centroid': False,\n",
    "    'zero_crossing_rate': False,\n",
    "    'harmonics': True,\n",
    "    'mel_spectrogram': False\n",
    "}\n",
    "\n",
    "# Extract Features for Augmented Data\n",
    "augmented_features_df = extract_features_from_signals(file_data, feature_toggles)\n",
    "\n",
    "# Replace NaN values with 0 in augmented_features_df\n",
    "augmented_features_df.fillna(0, inplace=True)\n",
    "\n",
    "# Clean 'id' and 'Label' columns\n",
    "augmented_features_df['id'] = augmented_features_df['id'].str.replace('.wav', '', regex=False)\n",
    "augmented_features_df['Label'] = augmented_features_df['Label'].str.lower().str.strip()  # Ensure labels are lowercase and stripped of spaces\n",
    "\n",
    "# Display Resulting DataFrame\n",
    "print(\"Extracted Features DataFrame (Cleaned Augmented Data):\")\n",
    "print(augmented_features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d206e015",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42c62ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Columns in Expanded DataFrame:\n",
      "Index(['id', 'Label', 'audio_signal', 'harmonics_1', 'harmonics_2',\n",
      "       'harmonics_3', 'harmonics_4', 'harmonics_5', 'harmonics_6',\n",
      "       'harmonics_7', 'harmonics_8', 'harmonics_9', 'harmonics_10',\n",
      "       'harmonics_11', 'harmonics_12', 'harmonics_13', 'harmonics_14',\n",
      "       'harmonics_15', 'harmonics_16', 'harmonics_17', 'harmonics_18',\n",
      "       'harmonics_19', 'harmonics_20', 'harmonics_21', 'intervals_1',\n",
      "       'intervals_2', 'intervals_3', 'intervals_4', 'intervals_5',\n",
      "       'intervals_6', 'intervals_7', 'intervals_8', 'intervals_9',\n",
      "       'intervals_10', 'intervals_11', 'intervals_12', 'intervals_13',\n",
      "       'intervals_14', 'intervals_15', 'intervals_16', 'intervals_17',\n",
      "       'intervals_18', 'intervals_19', 'intervals_20'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def expand_features(df, features_to_expand):\n",
    "    expanded_df = df.copy()\n",
    "    for feature in features_to_expand:\n",
    "        if feature in df.columns:\n",
    "            # Expand each list/array into separate columns with appropriate prefix\n",
    "            expanded_features = pd.DataFrame(df[feature].tolist(), index=df.index)\n",
    "            expanded_features.columns = [f'{feature}_{i+1}' for i in range(expanded_features.shape[1])]\n",
    "            # Add the expanded columns to the original dataframe and drop the original\n",
    "            expanded_df = pd.concat([expanded_df, expanded_features], axis=1).drop(columns=[feature])\n",
    "    return expanded_df\n",
    "\n",
    "# Expand harmonics and intervals in the raw data\n",
    "features_to_expand = ['harmonics', 'intervals']\n",
    "expanded_raw_features_df = expand_features(raw_features_df, features_to_expand)\n",
    "\n",
    "print(\"Available Columns in Expanded DataFrame:\")\n",
    "print(expanded_raw_features_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe06a2c",
   "metadata": {},
   "source": [
    "#### Ratios Between Specific Harmonics\n",
    "\n",
    "While harmonic frequencies and intervals between them are useful, the way they relate to major vs minor chords could be more nuanced than just the interval values (like we are using). Major and minor chords differ mainly in the 3rd interval (major third vs minor third). We will focus on specific intervals or harmonic relationships that are known to differentiate major and minor chords.\n",
    "\n",
    "We will compute the ratio between the 1st harmonic and the 3rd harmonic for each chord - and use that as a new feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "011adbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features DataFrame with Harmonic Ratios:\n",
      "          id  Label  ratio_1_to_2  ratio_1_to_3  ratio_1_to_4  ratio_1_to_5  \\\n",
      "0    Major_0  major      1.500000      2.000000      2.500000      3.000000   \n",
      "1    Major_1  major      1.333333      1.666667      2.000000      2.555556   \n",
      "2   Major_10  major      1.500000      2.000000      2.833333      3.666667   \n",
      "3  Major_100  major      1.285714      2.000000      2.571429      3.142857   \n",
      "4  Major_101  major      1.285714      2.285714      3.142857      3.714286   \n",
      "\n",
      "   ratio_1_to_6  ratio_1_to_7  ratio_1_to_8  ratio_1_to_9  ...  \\\n",
      "0      4.000000      4.500000      5.166667      6.166667  ...   \n",
      "1      3.000000      3.444444      5.111111      0.000000  ...   \n",
      "2      4.333333      5.166667      5.500000      7.166667  ...   \n",
      "3      3.714286      4.571429      5.142857      5.571429  ...   \n",
      "4      4.142857      5.142857      0.000000      0.000000  ...   \n",
      "\n",
      "   ratio_15_to_21  ratio_16_to_20  ratio_16_to_21  ratio_17_to_20  \\\n",
      "0             0.0             0.0             0.0             0.0   \n",
      "1             0.0             0.0             0.0             0.0   \n",
      "2             0.0             0.0             0.0             0.0   \n",
      "3             0.0             0.0             0.0             0.0   \n",
      "4             0.0             0.0             0.0             0.0   \n",
      "\n",
      "   ratio_17_to_21  ratio_18_to_20  ratio_18_to_21  ratio_19_to_20  \\\n",
      "0             0.0             0.0             0.0             0.0   \n",
      "1             0.0             0.0             0.0             0.0   \n",
      "2             0.0             0.0             0.0             0.0   \n",
      "3             0.0             0.0             0.0             0.0   \n",
      "4             0.0             0.0             0.0             0.0   \n",
      "\n",
      "   ratio_19_to_21  ratio_20_to_21  \n",
      "0             0.0             0.0  \n",
      "1             0.0             0.0  \n",
      "2             0.0             0.0  \n",
      "3             0.0             0.0  \n",
      "4             0.0             0.0  \n",
      "\n",
      "[5 rows x 212 columns]\n"
     ]
    }
   ],
   "source": [
    "# Copy the raw features dataframe\n",
    "features_df = raw_features_df.copy()\n",
    "\n",
    "# Standardized Function to Extract Harmonic Ratios\n",
    "def extract_harmonic_ratios_standardized(df):\n",
    "    harmonic_ratios = []\n",
    "    for idx, row in df.iterrows():\n",
    "        ratios = {}\n",
    "        harmonics = row['harmonics']\n",
    "\n",
    "        # Ensure harmonics is a list or array and contains more than one value\n",
    "        if isinstance(harmonics, (list, np.ndarray)) and len(harmonics) > 1:\n",
    "            # Use itertools.combinations to get all pairs (i, j) with i < j\n",
    "            for i, j in itertools.combinations(range(len(harmonics)), 2):\n",
    "                # Always use the lower index as the denominator to ensure consistency\n",
    "                if harmonics[i] > 1e-6:  # Avoid division by zero or near-zero values\n",
    "                    ratio_key = f'ratio_{i+1}_to_{j+1}'  # Naming convention: low index to high index\n",
    "                    ratios[ratio_key] = harmonics[j] / harmonics[i]\n",
    "                else:\n",
    "                    ratios[ratio_key] = np.nan\n",
    "\n",
    "        harmonic_ratios.append(ratios)\n",
    "    \n",
    "    # Convert harmonic ratios to DataFrame and ensure proper numeric type\n",
    "    harmonic_ratios_df = pd.DataFrame(harmonic_ratios).apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Extract only the id and Label columns from the original dataframe\n",
    "    id_label_df = df[['id', 'Label']].reset_index(drop=True)\n",
    "    \n",
    "    # Concatenate id, Label, and harmonic ratios into a new DataFrame\n",
    "    ratios_df = pd.concat([id_label_df, harmonic_ratios_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    return ratios_df\n",
    "\n",
    "# Apply the function to expand selected harmonic ratios (for evaluation)\n",
    "features_with_ratios_df = extract_harmonic_ratios_standardized(features_df)\n",
    "\n",
    "# Replace NaN values with 0 for simplicity in evaluation\n",
    "features_with_ratios_df.fillna(0, inplace=True)\n",
    "\n",
    "# Display a few rows for validation\n",
    "print(\"Features DataFrame with Harmonic Ratios:\")\n",
    "print(features_with_ratios_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "085c24ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Harmonic Ratios Selected: ['ratio_1_to_2', 'ratio_1_to_3', 'ratio_1_to_4', 'ratio_1_to_5', 'ratio_1_to_6', 'ratio_1_to_7', 'ratio_1_to_8', 'ratio_1_to_9', 'ratio_1_to_10', 'ratio_1_to_11', 'ratio_1_to_12', 'ratio_1_to_13', 'ratio_1_to_14', 'ratio_1_to_15', 'ratio_2_to_3', 'ratio_2_to_4', 'ratio_2_to_5', 'ratio_2_to_6', 'ratio_2_to_7', 'ratio_2_to_8', 'ratio_2_to_9', 'ratio_2_to_10', 'ratio_2_to_11', 'ratio_2_to_12', 'ratio_2_to_13', 'ratio_2_to_14', 'ratio_2_to_15', 'ratio_3_to_4', 'ratio_3_to_5', 'ratio_3_to_6', 'ratio_3_to_7', 'ratio_3_to_8', 'ratio_3_to_9', 'ratio_3_to_10', 'ratio_3_to_11', 'ratio_3_to_12', 'ratio_3_to_13', 'ratio_3_to_14', 'ratio_3_to_15', 'ratio_4_to_5', 'ratio_4_to_6', 'ratio_4_to_7', 'ratio_4_to_8', 'ratio_4_to_9', 'ratio_4_to_10', 'ratio_4_to_11', 'ratio_4_to_12', 'ratio_4_to_13', 'ratio_4_to_14', 'ratio_4_to_15', 'ratio_5_to_6', 'ratio_5_to_7', 'ratio_5_to_8', 'ratio_5_to_9', 'ratio_5_to_10', 'ratio_5_to_11', 'ratio_5_to_12', 'ratio_5_to_13', 'ratio_5_to_14', 'ratio_5_to_15', 'ratio_6_to_7', 'ratio_6_to_8', 'ratio_6_to_9', 'ratio_6_to_10', 'ratio_6_to_11', 'ratio_6_to_12', 'ratio_6_to_13', 'ratio_6_to_14', 'ratio_6_to_15', 'ratio_7_to_8', 'ratio_7_to_9', 'ratio_7_to_10', 'ratio_7_to_11', 'ratio_7_to_12', 'ratio_7_to_13', 'ratio_7_to_14', 'ratio_7_to_15', 'ratio_8_to_9', 'ratio_8_to_10', 'ratio_8_to_11', 'ratio_8_to_12', 'ratio_8_to_13', 'ratio_8_to_14', 'ratio_8_to_15', 'ratio_9_to_10', 'ratio_9_to_11', 'ratio_9_to_12', 'ratio_9_to_13', 'ratio_9_to_14', 'ratio_9_to_15', 'ratio_10_to_11', 'ratio_10_to_12', 'ratio_10_to_13', 'ratio_10_to_14', 'ratio_10_to_15', 'ratio_11_to_12', 'ratio_11_to_13', 'ratio_11_to_14', 'ratio_11_to_15', 'ratio_12_to_13', 'ratio_12_to_14', 'ratio_12_to_15', 'ratio_13_to_14', 'ratio_13_to_15', 'ratio_14_to_15', 'ratio_1_to_16', 'ratio_2_to_16', 'ratio_3_to_16', 'ratio_4_to_16', 'ratio_5_to_16', 'ratio_6_to_16', 'ratio_7_to_16', 'ratio_8_to_16', 'ratio_9_to_16', 'ratio_10_to_16', 'ratio_11_to_16', 'ratio_12_to_16', 'ratio_13_to_16', 'ratio_14_to_16', 'ratio_15_to_16', 'ratio_1_to_17', 'ratio_2_to_17', 'ratio_3_to_17', 'ratio_4_to_17', 'ratio_5_to_17', 'ratio_6_to_17', 'ratio_7_to_17', 'ratio_8_to_17', 'ratio_9_to_17', 'ratio_10_to_17', 'ratio_11_to_17', 'ratio_12_to_17', 'ratio_13_to_17', 'ratio_14_to_17', 'ratio_15_to_17', 'ratio_16_to_17', 'ratio_1_to_18', 'ratio_1_to_19', 'ratio_2_to_18', 'ratio_2_to_19', 'ratio_3_to_18', 'ratio_3_to_19', 'ratio_4_to_18', 'ratio_4_to_19', 'ratio_5_to_18', 'ratio_5_to_19', 'ratio_6_to_18', 'ratio_6_to_19', 'ratio_7_to_18', 'ratio_7_to_19', 'ratio_8_to_18', 'ratio_8_to_19', 'ratio_9_to_18', 'ratio_9_to_19', 'ratio_10_to_18', 'ratio_10_to_19', 'ratio_11_to_18', 'ratio_11_to_19', 'ratio_12_to_18', 'ratio_12_to_19', 'ratio_13_to_18', 'ratio_13_to_19', 'ratio_14_to_18', 'ratio_14_to_19', 'ratio_15_to_18', 'ratio_15_to_19', 'ratio_16_to_18', 'ratio_16_to_19', 'ratio_17_to_18', 'ratio_17_to_19', 'ratio_18_to_19', 'ratio_1_to_20', 'ratio_1_to_21', 'ratio_2_to_20', 'ratio_2_to_21', 'ratio_3_to_20', 'ratio_3_to_21', 'ratio_4_to_20', 'ratio_4_to_21', 'ratio_5_to_20', 'ratio_5_to_21', 'ratio_6_to_20', 'ratio_6_to_21', 'ratio_7_to_20', 'ratio_7_to_21', 'ratio_8_to_20', 'ratio_8_to_21', 'ratio_9_to_21']\n"
     ]
    }
   ],
   "source": [
    "# Filter Harmonic Ratios Based on Variance\n",
    "def filter_low_variance_ratios(df, threshold=0.01):\n",
    "    ratio_columns = [col for col in df.columns if 'ratio_' in col]\n",
    "    selected_columns = []\n",
    "\n",
    "    # Loop over each ratio column to calculate variance and filter\n",
    "    for col in ratio_columns:\n",
    "        variance = df[col].var()\n",
    "        if variance > threshold:\n",
    "            selected_columns.append(col)\n",
    "\n",
    "    return selected_columns\n",
    "\n",
    "# Select harmonic ratio columns with sufficient variance\n",
    "selected_harmonic_ratios = filter_low_variance_ratios(features_with_ratios_df)\n",
    "\n",
    "# Print the selected ratios\n",
    "if selected_harmonic_ratios:\n",
    "    print(f\"\\nTop Harmonic Ratios Selected: {selected_harmonic_ratios}\")\n",
    "else:\n",
    "    print(\"\\nNo harmonic ratios were selected after filtering by variance.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b88a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Evaluation for Harmonic Ratios with Enhanced Robustness\n",
    "def evaluate_harmonic_ratios(df, selected_ratios, label_column='Label', p_value_threshold=0.05, epsilon=1e-6, apply_correction=False):\n",
    "    ratios_stats = []\n",
    "    for ratio in selected_ratios:\n",
    "        if ratio in df.columns:\n",
    "            major_values = df[df[label_column] == 'Major'][ratio].dropna()\n",
    "            minor_values = df[df[label_column] == 'Minor'][ratio].dropna()\n",
    "\n",
    "            # Perform t-test and calculate Cohen's d if both groups are non-empty\n",
    "            if len(major_values) > 1 and len(minor_values) > 1:\n",
    "                # Perform t-test using scipy.stats\n",
    "                t_stat, p_value = stats.ttest_ind(major_values, minor_values, equal_var=False)\n",
    "                \n",
    "                # Calculate Cohen's d with epsilon for numerical stability\n",
    "                pooled_var = (major_values.var(ddof=1) + minor_values.var(ddof=1)) / 2\n",
    "                cohens_d = (major_values.mean() - minor_values.mean()) / np.sqrt(pooled_var + epsilon)\n",
    "                \n",
    "                # Append the stats\n",
    "                ratios_stats.append({'ratio': ratio, 'p_value': p_value, 'cohens_d': cohens_d})\n",
    "\n",
    "    # Apply Multiple Comparisons Correction if needed\n",
    "    if apply_correction and ratios_stats:\n",
    "        p_values = [r_stat['p_value'] for r_stat in ratios_stats]\n",
    "        # Apply Benjamini-Hochberg correction\n",
    "        reject, corrected_p_values, _, _ = multipletests(p_values, alpha=p_value_threshold, method='fdr_bh')\n",
    "        \n",
    "        # Update the ratios_stats with corrected p-values and significance\n",
    "        for i, r_stat in enumerate(ratios_stats):\n",
    "            r_stat['corrected_p_value'] = corrected_p_values[i]\n",
    "            r_stat['significant'] = reject[i]\n",
    "        # Sort by corrected p-value ascending\n",
    "        ratios_stats = sorted(ratios_stats, key=lambda x: x['corrected_p_value'])\n",
    "    else:\n",
    "        # Sort by p-value ascending without correction\n",
    "        ratios_stats = sorted(ratios_stats, key=lambda x: x['p_value'])\n",
    "    \n",
    "    return ratios_stats\n",
    "\n",
    "# Apply the Evaluation Function to the Expanded DataFrame\n",
    "ratios_stats = evaluate_harmonic_ratios(features_with_ratios_df, selected_harmonic_ratios, apply_correction=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ed55365",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    # Harmonic Ratios Based on Statistical and Visual Evaluation\n",
    "    'ratio_5_to_12', 'ratio_5_to_10', 'ratio_10_to_14', 'ratio_10_to_12', \n",
    "    'ratio_5_to_15', 'ratio_7_to_13', 'ratio_7_to_15', 'ratio_10_to_13', \n",
    "    'ratio_1_to_9', 'ratio_5_to_16', 'ratio_10_to_15', 'ratio_1_to_4', \n",
    "    'ratio_5_to_9', 'ratio_7_to_9', 'ratio_2_to_3', 'ratio_3_to_12', \n",
    "    'ratio_6_to_15', 'ratio_5_to_13'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcb2d6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Label</th>\n",
       "      <th>ratio_5_to_12</th>\n",
       "      <th>ratio_5_to_10</th>\n",
       "      <th>ratio_10_to_14</th>\n",
       "      <th>ratio_10_to_12</th>\n",
       "      <th>ratio_5_to_15</th>\n",
       "      <th>ratio_7_to_13</th>\n",
       "      <th>ratio_7_to_15</th>\n",
       "      <th>ratio_10_to_13</th>\n",
       "      <th>ratio_1_to_9</th>\n",
       "      <th>ratio_5_to_16</th>\n",
       "      <th>ratio_10_to_15</th>\n",
       "      <th>ratio_1_to_4</th>\n",
       "      <th>ratio_5_to_9</th>\n",
       "      <th>ratio_7_to_9</th>\n",
       "      <th>ratio_2_to_3</th>\n",
       "      <th>ratio_3_to_12</th>\n",
       "      <th>ratio_6_to_15</th>\n",
       "      <th>ratio_5_to_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Major_0</td>\n",
       "      <td>major</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>1.586957</td>\n",
       "      <td>1.173913</td>\n",
       "      <td>4.722222</td>\n",
       "      <td>2.259259</td>\n",
       "      <td>3.148148</td>\n",
       "      <td>1.326087</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.847826</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>1.370370</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.541667</td>\n",
       "      <td>3.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Major_1</td>\n",
       "      <td>major</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Major_10</td>\n",
       "      <td>major</td>\n",
       "      <td>2.772727</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.326087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.096774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.413043</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>1.954545</td>\n",
       "      <td>1.387097</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Major_100</td>\n",
       "      <td>major</td>\n",
       "      <td>2.318182</td>\n",
       "      <td>1.954545</td>\n",
       "      <td>1.813953</td>\n",
       "      <td>1.186047</td>\n",
       "      <td>4.136364</td>\n",
       "      <td>2.031250</td>\n",
       "      <td>2.843750</td>\n",
       "      <td>1.511628</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.116279</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>1.772727</td>\n",
       "      <td>1.218750</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>3.642857</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Major_101</td>\n",
       "      <td>major</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  Label  ratio_5_to_12  ratio_5_to_10  ratio_10_to_14  \\\n",
       "0    Major_0  major       3.000000       2.555556        1.586957   \n",
       "1    Major_1  major       0.000000       0.000000        0.000000   \n",
       "2   Major_10  major       2.772727       2.090909        0.000000   \n",
       "3  Major_100  major       2.318182       1.954545        1.813953   \n",
       "4  Major_101  major       0.000000       0.000000        0.000000   \n",
       "\n",
       "   ratio_10_to_12  ratio_5_to_15  ratio_7_to_13  ratio_7_to_15  \\\n",
       "0        1.173913       4.722222       2.259259       3.148148   \n",
       "1        0.000000       0.000000       0.000000       0.000000   \n",
       "2        1.326087       0.000000       2.096774       0.000000   \n",
       "3        1.186047       4.136364       2.031250       2.843750   \n",
       "4        0.000000       0.000000       0.000000       0.000000   \n",
       "\n",
       "   ratio_10_to_13  ratio_1_to_9  ratio_5_to_16  ratio_10_to_15  ratio_1_to_4  \\\n",
       "0        1.326087      6.166667            0.0        1.847826      2.500000   \n",
       "1        0.000000      0.000000            0.0        0.000000      2.000000   \n",
       "2        1.413043      7.166667            0.0        0.000000      2.833333   \n",
       "3        1.511628      5.571429            0.0        2.116279      2.571429   \n",
       "4        0.000000      0.000000            0.0        0.000000      3.142857   \n",
       "\n",
       "   ratio_5_to_9  ratio_7_to_9  ratio_2_to_3  ratio_3_to_12  ratio_6_to_15  \\\n",
       "0      2.055556      1.370370      1.333333       4.500000       3.541667   \n",
       "1      0.000000      0.000000      1.250000       0.000000       0.000000   \n",
       "2      1.954545      1.387097      1.333333       5.083333       0.000000   \n",
       "3      1.772727      1.218750      1.555556       3.642857       3.500000   \n",
       "4      0.000000      0.000000      1.777778       0.000000       0.000000   \n",
       "\n",
       "   ratio_5_to_13  \n",
       "0       3.388889  \n",
       "1       0.000000  \n",
       "2       2.954545  \n",
       "3       2.954545  \n",
       "4       0.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_raw_ratios_df = features_with_ratios_df[['id', 'Label'] + selected_features]\n",
    "\n",
    "filtered_raw_ratios_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d193a77b",
   "metadata": {},
   "source": [
    "---\n",
    "#### Feature Engineering for Augmented Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14f5f6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of Augmented Ratios DataFrame:\n",
      "          id  Label  ratio_1_to_2  ratio_1_to_3  ratio_1_to_4  ratio_1_to_5  \\\n",
      "0    Major_0  major      1.500000      2.000000      2.500000      3.000000   \n",
      "1    Major_1  major      1.333333      1.666667      2.000000      2.555556   \n",
      "2   Major_10  major      1.500000      2.000000      2.833333      3.666667   \n",
      "3  Major_100  major      1.285714      2.000000      2.571429      3.142857   \n",
      "4  Major_101  major      1.285714      2.285714      3.142857      3.714286   \n",
      "\n",
      "   ratio_1_to_6  ratio_1_to_7  ratio_1_to_8  ratio_1_to_9  ...  \\\n",
      "0      4.000000      4.500000      5.166667      6.166667  ...   \n",
      "1      3.000000      3.444444      5.111111      0.000000  ...   \n",
      "2      4.333333      5.166667      5.500000      7.166667  ...   \n",
      "3      3.714286      4.571429      5.142857      5.571429  ...   \n",
      "4      4.142857      5.142857      0.000000      0.000000  ...   \n",
      "\n",
      "   ratio_15_to_21  ratio_16_to_20  ratio_16_to_21  ratio_17_to_20  \\\n",
      "0             0.0             0.0             0.0             0.0   \n",
      "1             0.0             0.0             0.0             0.0   \n",
      "2             0.0             0.0             0.0             0.0   \n",
      "3             0.0             0.0             0.0             0.0   \n",
      "4             0.0             0.0             0.0             0.0   \n",
      "\n",
      "   ratio_17_to_21  ratio_18_to_20  ratio_18_to_21  ratio_19_to_20  \\\n",
      "0             0.0             0.0             0.0             0.0   \n",
      "1             0.0             0.0             0.0             0.0   \n",
      "2             0.0             0.0             0.0             0.0   \n",
      "3             0.0             0.0             0.0             0.0   \n",
      "4             0.0             0.0             0.0             0.0   \n",
      "\n",
      "   ratio_19_to_21  ratio_20_to_21  \n",
      "0             0.0             0.0  \n",
      "1             0.0             0.0  \n",
      "2             0.0             0.0  \n",
      "3             0.0             0.0  \n",
      "4             0.0             0.0  \n",
      "\n",
      "[5 rows x 212 columns]\n"
     ]
    }
   ],
   "source": [
    "# Expand Harmonic Ratios Between All Pairs for Evaluation (For Augmented Data)\n",
    "def extract_harmonic_ratios_augmented(df):\n",
    "    harmonic_ratios = []\n",
    "    for idx, row in df.iterrows():\n",
    "        ratios = {}\n",
    "        harmonics = row['harmonics']\n",
    "\n",
    "        # Ensure harmonics is a list or array and contains more than one value\n",
    "        if isinstance(harmonics, (list, np.ndarray)) and len(harmonics) > 1:\n",
    "            # Filter out zero or near-zero harmonics to avoid invalid ratios\n",
    "            harmonics = [h for h in harmonics if h > 1e-6]\n",
    "            if len(harmonics) > 1:\n",
    "                # Calculate ratios between all possible harmonic pairs\n",
    "                for i, j in itertools.combinations(range(len(harmonics)), 2):\n",
    "                    ratio_key = f'ratio_{i+1}_to_{j+1}'\n",
    "                    if harmonics[i] != 0:  # Avoid division by zero\n",
    "                        ratios[ratio_key] = harmonics[j] / harmonics[i]\n",
    "                    else:\n",
    "                        ratios[ratio_key] = np.nan\n",
    "\n",
    "        harmonic_ratios.append(ratios)\n",
    "    \n",
    "    # Convert harmonic ratios to DataFrame and ensure proper numeric type\n",
    "    harmonic_ratios_df = pd.DataFrame(harmonic_ratios).apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Extract only the id and Label columns from the original dataframe\n",
    "    id_label_df = df[['id', 'Label']].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Concatenate id, Label, and harmonic ratios into a new DataFrame\n",
    "    augmented_ratios_df = pd.concat([id_label_df, harmonic_ratios_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    return augmented_ratios_df\n",
    "\n",
    "# Apply the Function to Extract Harmonic Ratios (for augmented data)\n",
    "augmented_ratios_df = extract_harmonic_ratios_augmented(augmented_features_df)\n",
    "\n",
    "# Replace NaN values with 0 for simplicity in evaluation\n",
    "augmented_ratios_df.fillna(0, inplace=True)\n",
    "\n",
    "# Displaying a few rows for validation\n",
    "print(\"\\nSample of Augmented Ratios DataFrame:\")\n",
    "print(augmented_ratios_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "847699ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Label</th>\n",
       "      <th>ratio_5_to_12</th>\n",
       "      <th>ratio_5_to_10</th>\n",
       "      <th>ratio_10_to_14</th>\n",
       "      <th>ratio_10_to_12</th>\n",
       "      <th>ratio_5_to_15</th>\n",
       "      <th>ratio_7_to_13</th>\n",
       "      <th>ratio_7_to_15</th>\n",
       "      <th>ratio_10_to_13</th>\n",
       "      <th>ratio_1_to_9</th>\n",
       "      <th>ratio_5_to_16</th>\n",
       "      <th>ratio_10_to_15</th>\n",
       "      <th>ratio_1_to_4</th>\n",
       "      <th>ratio_5_to_9</th>\n",
       "      <th>ratio_7_to_9</th>\n",
       "      <th>ratio_2_to_3</th>\n",
       "      <th>ratio_3_to_12</th>\n",
       "      <th>ratio_6_to_15</th>\n",
       "      <th>ratio_5_to_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Major_0</td>\n",
       "      <td>major</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>1.586957</td>\n",
       "      <td>1.173913</td>\n",
       "      <td>4.722222</td>\n",
       "      <td>2.259259</td>\n",
       "      <td>3.148148</td>\n",
       "      <td>1.326087</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.847826</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>1.370370</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.541667</td>\n",
       "      <td>3.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Major_1</td>\n",
       "      <td>major</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Major_10</td>\n",
       "      <td>major</td>\n",
       "      <td>2.772727</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.326087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.096774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.413043</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>1.954545</td>\n",
       "      <td>1.387097</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Major_100</td>\n",
       "      <td>major</td>\n",
       "      <td>2.318182</td>\n",
       "      <td>1.954545</td>\n",
       "      <td>1.813953</td>\n",
       "      <td>1.186047</td>\n",
       "      <td>4.136364</td>\n",
       "      <td>2.031250</td>\n",
       "      <td>2.843750</td>\n",
       "      <td>1.511628</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.116279</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>1.772727</td>\n",
       "      <td>1.218750</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>3.642857</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Major_101</td>\n",
       "      <td>major</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  Label  ratio_5_to_12  ratio_5_to_10  ratio_10_to_14  \\\n",
       "0    Major_0  major       3.000000       2.555556        1.586957   \n",
       "1    Major_1  major       0.000000       0.000000        0.000000   \n",
       "2   Major_10  major       2.772727       2.090909        0.000000   \n",
       "3  Major_100  major       2.318182       1.954545        1.813953   \n",
       "4  Major_101  major       0.000000       0.000000        0.000000   \n",
       "\n",
       "   ratio_10_to_12  ratio_5_to_15  ratio_7_to_13  ratio_7_to_15  \\\n",
       "0        1.173913       4.722222       2.259259       3.148148   \n",
       "1        0.000000       0.000000       0.000000       0.000000   \n",
       "2        1.326087       0.000000       2.096774       0.000000   \n",
       "3        1.186047       4.136364       2.031250       2.843750   \n",
       "4        0.000000       0.000000       0.000000       0.000000   \n",
       "\n",
       "   ratio_10_to_13  ratio_1_to_9  ratio_5_to_16  ratio_10_to_15  ratio_1_to_4  \\\n",
       "0        1.326087      6.166667            0.0        1.847826      2.500000   \n",
       "1        0.000000      0.000000            0.0        0.000000      2.000000   \n",
       "2        1.413043      7.166667            0.0        0.000000      2.833333   \n",
       "3        1.511628      5.571429            0.0        2.116279      2.571429   \n",
       "4        0.000000      0.000000            0.0        0.000000      3.142857   \n",
       "\n",
       "   ratio_5_to_9  ratio_7_to_9  ratio_2_to_3  ratio_3_to_12  ratio_6_to_15  \\\n",
       "0      2.055556      1.370370      1.333333       4.500000       3.541667   \n",
       "1      0.000000      0.000000      1.250000       0.000000       0.000000   \n",
       "2      1.954545      1.387097      1.333333       5.083333       0.000000   \n",
       "3      1.772727      1.218750      1.555556       3.642857       3.500000   \n",
       "4      0.000000      0.000000      1.777778       0.000000       0.000000   \n",
       "\n",
       "   ratio_5_to_13  \n",
       "0       3.388889  \n",
       "1       0.000000  \n",
       "2       2.954545  \n",
       "3       2.954545  \n",
       "4       0.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_augmented_ratios_df = augmented_ratios_df[['id', 'Label'] + selected_features]\n",
    "\n",
    "filtered_augmented_ratios_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d56ca2",
   "metadata": {},
   "source": [
    "---\n",
    "## Modeling\n",
    "\n",
    "- [ ] Runs and interprets a simple, baseline model for comparison\n",
    "- [ ] Introduces new models that improve on prior models and interprets their results\n",
    "- [ ] Explicitly justifies model changes based on the results of prior models and the problem context\n",
    "- [ ] Explicitly describes any improvements found from running new models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e140b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Toggles\n",
    "model_toggles = {\n",
    "    'chroma': False,\n",
    "    'mfcc': False,\n",
    "    'spectral_centroid': False,\n",
    "    'zero_crossing_rate': False,\n",
    "    'harmonics': False,\n",
    "    'intervals': False,\n",
    "    'mel_spectrogram': False,\n",
    "    'harmonic_ratios': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ab564d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_model_data(model_toggles, use_augmentation=False):\n",
    "    # Start with raw features\n",
    "    model = raw_features_df.copy()\n",
    "\n",
    "    # Merge with harmonic ratios if toggled on\n",
    "    if model_toggles['harmonic_ratios']:\n",
    "        model = model.merge(filtered_raw_ratios_df, on='id', how='left')\n",
    "\n",
    "    # Handle augmentation, but don't merge with raw yet\n",
    "    if use_augmentation:\n",
    "        a_model = augmented_features_df.copy()\n",
    "\n",
    "        # Merge with harmonic ratios for augmented data if toggled on\n",
    "        if model_toggles['harmonic_ratios']:\n",
    "            a_model = a_model.merge(filtered_augmented_ratios_df, on='id', how='left')\n",
    "\n",
    "    # Drop columns from both model and a_model based on feature toggles\n",
    "    columns_to_drop = []\n",
    "    for feature, use_feature in model_toggles.items():\n",
    "        if not use_feature and feature in model.columns:\n",
    "            columns_to_drop.append(feature)\n",
    "\n",
    "    # Always drop the raw audio signal\n",
    "    if 'audio_signal' in model.columns:\n",
    "        columns_to_drop.append('audio_signal')\n",
    "\n",
    "    # Drop the identified columns in both dataframes\n",
    "    model.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "    if use_augmentation:\n",
    "        a_model.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "    # Handle duplicate Label columns\n",
    "    for df in [model, a_model if use_augmentation else None]:\n",
    "        if df is not None:\n",
    "            if 'Label_x' in df.columns and 'Label_y' in df.columns:\n",
    "                df.drop(columns=['Label_y'], inplace=True)\n",
    "                df.rename(columns={'Label_x': 'Label'}, inplace=True)\n",
    "            elif 'Label_x' in df.columns:\n",
    "                df.rename(columns={'Label_x': 'Label'}, inplace=True)\n",
    "            elif 'Label_y' in df.columns:\n",
    "                df.rename(columns={'Label_y': 'Label'}, inplace=True)\n",
    "\n",
    "    # Return both model and a_model\n",
    "    if use_augmentation:\n",
    "        return model, a_model\n",
    "\n",
    "    return model, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a88cc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Raw Model Data:\n",
      "          id  Label  ratio_5_to_12  ratio_5_to_10  ratio_10_to_14  \\\n",
      "0    Major_0  major       3.000000       2.555556        1.586957   \n",
      "1    Major_1  major       0.000000       0.000000        0.000000   \n",
      "2   Major_10  major       2.772727       2.090909        0.000000   \n",
      "3  Major_100  major       2.318182       1.954545        1.813953   \n",
      "4  Major_101  major       0.000000       0.000000        0.000000   \n",
      "\n",
      "   ratio_10_to_12  ratio_5_to_15  ratio_7_to_13  ratio_7_to_15  \\\n",
      "0        1.173913       4.722222       2.259259       3.148148   \n",
      "1        0.000000       0.000000       0.000000       0.000000   \n",
      "2        1.326087       0.000000       2.096774       0.000000   \n",
      "3        1.186047       4.136364       2.031250       2.843750   \n",
      "4        0.000000       0.000000       0.000000       0.000000   \n",
      "\n",
      "   ratio_10_to_13  ratio_1_to_9  ratio_5_to_16  ratio_10_to_15  ratio_1_to_4  \\\n",
      "0        1.326087      6.166667            0.0        1.847826      2.500000   \n",
      "1        0.000000      0.000000            0.0        0.000000      2.000000   \n",
      "2        1.413043      7.166667            0.0        0.000000      2.833333   \n",
      "3        1.511628      5.571429            0.0        2.116279      2.571429   \n",
      "4        0.000000      0.000000            0.0        0.000000      3.142857   \n",
      "\n",
      "   ratio_5_to_9  ratio_7_to_9  ratio_2_to_3  ratio_3_to_12  ratio_6_to_15  \\\n",
      "0      2.055556      1.370370      1.333333       4.500000       3.541667   \n",
      "1      0.000000      0.000000      1.250000       0.000000       0.000000   \n",
      "2      1.954545      1.387097      1.333333       5.083333       0.000000   \n",
      "3      1.772727      1.218750      1.555556       3.642857       3.500000   \n",
      "4      0.000000      0.000000      1.777778       0.000000       0.000000   \n",
      "\n",
      "   ratio_5_to_13  \n",
      "0       3.388889  \n",
      "1       0.000000  \n",
      "2       2.954545  \n",
      "3       2.954545  \n",
      "4       0.000000  \n",
      "\n",
      "Filtered Augmented Model Data:\n",
      "          id  Label  ratio_5_to_12  ratio_5_to_10  ratio_10_to_14  \\\n",
      "0    Major_0  major       3.000000       2.555556        1.586957   \n",
      "1    Major_1  major       0.000000       0.000000        0.000000   \n",
      "2   Major_10  major       2.772727       2.090909        0.000000   \n",
      "3  Major_100  major       2.318182       1.954545        1.813953   \n",
      "4  Major_101  major       0.000000       0.000000        0.000000   \n",
      "\n",
      "   ratio_10_to_12  ratio_5_to_15  ratio_7_to_13  ratio_7_to_15  \\\n",
      "0        1.173913       4.722222       2.259259       3.148148   \n",
      "1        0.000000       0.000000       0.000000       0.000000   \n",
      "2        1.326087       0.000000       2.096774       0.000000   \n",
      "3        1.186047       4.136364       2.031250       2.843750   \n",
      "4        0.000000       0.000000       0.000000       0.000000   \n",
      "\n",
      "   ratio_10_to_13  ratio_1_to_9  ratio_5_to_16  ratio_10_to_15  ratio_1_to_4  \\\n",
      "0        1.326087      6.166667            0.0        1.847826      2.500000   \n",
      "1        0.000000      0.000000            0.0        0.000000      2.000000   \n",
      "2        1.413043      7.166667            0.0        0.000000      2.833333   \n",
      "3        1.511628      5.571429            0.0        2.116279      2.571429   \n",
      "4        0.000000      0.000000            0.0        0.000000      3.142857   \n",
      "\n",
      "   ratio_5_to_9  ratio_7_to_9  ratio_2_to_3  ratio_3_to_12  ratio_6_to_15  \\\n",
      "0      2.055556      1.370370      1.333333       4.500000       3.541667   \n",
      "1      0.000000      0.000000      1.250000       0.000000       0.000000   \n",
      "2      1.954545      1.387097      1.333333       5.083333       0.000000   \n",
      "3      1.772727      1.218750      1.555556       3.642857       3.500000   \n",
      "4      0.000000      0.000000      1.777778       0.000000       0.000000   \n",
      "\n",
      "   ratio_5_to_13  \n",
      "0       3.388889  \n",
      "1       0.000000  \n",
      "2       2.954545  \n",
      "3       2.954545  \n",
      "4       0.000000  \n",
      "Shape of Augmented Model Data: (858, 20)\n",
      "Shape of Raw Model Data: (858, 20)\n"
     ]
    }
   ],
   "source": [
    "raw_model_data, augmented_model_data = filter_model_data(model_toggles, use_augmentation=True)\n",
    "\n",
    "# Display the resulting dataframes for validation\n",
    "print(\"\\nFiltered Raw Model Data:\")\n",
    "print(raw_model_data.head())\n",
    "\n",
    "if augmented_model_data is not None:\n",
    "    print(\"\\nFiltered Augmented Model Data:\")\n",
    "    print(augmented_model_data.head())\n",
    "    print(f\"Shape of Augmented Model Data: {augmented_model_data.shape}\")\n",
    "else:\n",
    "    print(\"\\nNo augmented data\")\n",
    "    \n",
    "print(f\"Shape of Raw Model Data: {raw_model_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "564d2a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (686, 18)\n",
      "Test set shape: (172, 18)\n"
     ]
    }
   ],
   "source": [
    "# Split raw_model_data into train and test sets\n",
    "X = raw_model_data.drop(columns=['Label'])\n",
    "y = raw_model_data['Label']\n",
    "\n",
    "# Save the IDs for tracking purposes\n",
    "ids = X['id']\n",
    "X = X.drop(columns=['id'])\n",
    "\n",
    "# Use stratified split to maintain balanced classes\n",
    "X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(\n",
    "    X, y, ids, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "693b95df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape after augmentation: (1544, 18)\n"
     ]
    }
   ],
   "source": [
    "# Handle augmentation if applicable\n",
    "if augmented_model_data is not None:\n",
    "    X_augmented = augmented_model_data.drop(columns=['id', 'Label'])\n",
    "    y_augmented = augmented_model_data['Label']\n",
    "    \n",
    "    # Concatenate augmented data with training data\n",
    "    X_train = pd.concat([X_train, X_augmented], ignore_index=True)\n",
    "    y_train = pd.concat([y_train, y_augmented], ignore_index=True)\n",
    "\n",
    "print(\"Train set shape after augmentation:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bcee677f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set scaled shape: (1544, 18)\n",
      "Test set scaled shape: (172, 18)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on the training data and transform the training set\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Training set scaled shape:\", X_train_scaled.shape)\n",
    "print(\"Test set scaled shape:\", X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bbb330b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model trained.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Random Forest model trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713f2c8e",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "- [ ] Justifies choice of metrics using context of the real-world problem and consequences of errors\n",
    "- [ ] Identifies one final model based on performance on the chosen metrics with validation data\n",
    "- [ ] Evaluates the performance of the final model using holdout test data\n",
    "- [ ] Discusses implications of the final model evaluation for solving the real-world problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06d38c81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       major       0.98      0.98      0.98       100\n",
      "       minor       0.97      0.97      0.97        72\n",
      "\n",
      "    accuracy                           0.98       172\n",
      "   macro avg       0.98      0.98      0.98       172\n",
      "weighted avg       0.98      0.98      0.98       172\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[98  2]\n",
      " [ 2 70]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ad9fe5",
   "metadata": {},
   "source": [
    "## Other Reqs\n",
    "\n",
    "#### Code Quality:\n",
    "\n",
    "Code is easy to read, using comments, spacing, variable names, and function docstrings\n",
    "All code runs and no code or comments are included that are not needed for the project \n",
    "Code minimizes repetition, using loops, functions, and classes\n",
    "Code adapted from others is properly cited with author names and location of the cited material\n",
    "\n",
    "#### GitHub Repo:\n",
    "- [ ] README.md includes concise summary of project with all data science steps\n",
    "- [ ] README.md links to presentation and sources\n",
    "- [ ] README.md includes instructions for navigating the repository\n",
    "- [ ] Files and folders are named briefly and descriptively, with consistent naming conventions\n",
    "- [ ] Files and folders are organized logically and consistently\n",
    "- [ ] Commit history includes regular commits with informative commit messages\n",
    "- [ ] Large or sensitive files are listed in .gitignore and not pushed to GitHub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6cb62a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              858\n",
       "Label           858\n",
       "audio_signal    858\n",
       "harmonics       858\n",
       "intervals       858\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_features_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c4934204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count existing samples in the original dataset\n",
    "original_counts = file_data['label'].value_counts()\n",
    "target_count = 500\n",
    "\n",
    "# Determine how many samples to augment for each class\n",
    "augmented_counts = {label: target_count - count if count < target_count else 0 for label, count in original_counts.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "212ac9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Major    502\n",
       "Minor    357\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d64e8d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Major': 0, 'Minor': 143}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e6c35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
